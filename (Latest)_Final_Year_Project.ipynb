{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wXFkbjsiMAq"
      },
      "source": [
        "# Dependency Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0U5hu5TiPlS",
        "outputId": "e0268fac-9aa9-4dd7-e65b-b256832c9fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.5)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.29)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.6)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.0.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.3.3)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.8.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.4.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eph8HxEXiFQ6"
      },
      "source": [
        "# Library Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9saV96oblLHi"
      },
      "outputs": [],
      "source": [
        "import os, sys, os.path\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-2AjoxviHfy",
        "outputId": "6b27b935-5845-4038-bb35-c20111a5bd40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "\n",
        "import gym\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjZYQ0IIjdbK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from scipy import spatial\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "import time\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import torchvision.transforms as transforms\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HgVu4e5rZ_M"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os, os.path\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models as torchvision_models\n",
        "import torchvision\n",
        "\n",
        "import subprocess\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.distributed as dist\n",
        "from PIL import ImageFilter, ImageOps\n",
        "import random\n",
        "import torch.distributed as dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R-8ZzGJWqmz"
      },
      "outputs": [],
      "source": [
        "from scipy import spatial\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os, os.path\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score,classification_report\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6GMw0HdICXN"
      },
      "outputs": [],
      "source": [
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b1NfrdnoO-P",
        "outputId": "c4d1e1bc-bd31-4df2-ad6a-0a7e81222f78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.3)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.1.1)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Add this in a Google Colab cell to install the correct version of Pytorch Geometric.\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "\n",
        "import networkx as nx\n",
        "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
        "from torch_geometric.data import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdDTNuF5r2Gx"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GATConv\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jzvxkgfDPP1"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as T\n",
        "from torch_geometric.transforms import ToSLIC\n",
        "from torch_geometric.nn import global_mean_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lST3cOAok_ea"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXUsieKqms9B"
      },
      "outputs": [],
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o36QCD4-lCCb"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "\"arch\":\"vit_small\" # choices=['vit_tiny', 'vit_small', 'vit_base', 'xcit', 'deit_tiny', 'deit_small'] help=\"\"\"Name of architecture to train. For quick experiments with ViTs,we recommend using vit_tiny or vit_small.\"\"\")\n",
        ",\"patch_size\":16 # help=Size in pixels of input square patches - default 16 (for 16x16 patches). Using smaller values leads to better performance but requires more memory\n",
        ",\"out_dim\": 65536 # help=Dimensionality of the DINO head output. For complex and large datasets large values (like 65k) work well.\n",
        ",\"norm_last_layer\":True #  help=Whether or not to weight normalize the last layer of the DINO head. Not normalizing leads to better performance but can make the training unstable. In our experiments, we typically set this paramater to False with vit_small and True with vit_base\n",
        ",\"momentum_teacher\":0.996 # help=\"\"\"Base EMA parameter for teacher update. The value is increased to 1 during training with cosine schedule. We recommend setting a higher value with small batches: for example use 0.9995 with batch size of 256.\"\"\"\n",
        ",\"use_bn_in_head\":False #help=Whether to use batch normalizations in projection head (Default: False)\n",
        "\n",
        "# Temperature teacher parameters\n",
        ",\"warmup_teacher_temp\":0.04 #  help=\"\"\"Initial value for the teacher temperature: 0.04 works well in most cases.Try decreasing it if the training loss does not decrease.\"\"\"\n",
        ",\"teacher_temp\":0.04 # help=\"\"\"Final value (after linear warmup) of the teacher temperature. For most experiments, anything above 0.07 is unstable. We recommend starting with the default value of 0.04 and increase this slightly if needed.\"\"\")\n",
        ",\"warmup_teacher_temp_epochs\":0 #help=Number of warmup epochs for the teacher temperature (Default: 30).#\n",
        "\n",
        "# Training/Optimization parameters\n",
        ",\"use_fp16\":True #help=Whether or not to use half precision for training. Improves training time and memory requirements, but can provoke instability and slight decay of performance. We recommend disabling mixed precision if the loss is unstable, if reducing the patch size or if training with bigger ViTs.#\n",
        ",\"weight_decay\":0.04 #help=Initial value of the weight decay. With ViT, a smaller value at the beginning of training works well.\n",
        ",\"weight_decay_end\":0.4 #help=Final value of the weight decay. We use a cosine schedule for WD and using a larger decay by the end of training improves performance for ViTs.#\n",
        ",\"clip_grad\":3.0 #help=Maximal parameter gradient norm if using gradient clipping. Clipping with norm .3 ~ 1.0 can help optimization for larger ViT architectures. 0 for disabling.#\n",
        ",\"batch_size_per_gpu\":64 #help=Per-GPU batch-size : number of distinct images loaded on one GPU.#\n",
        ",\"epochs\":20 #help=Number of epochs of training.#\n",
        ",\"freeze_last_layer\":1 #help=Number of epochs during which we keep the output layer fixed. Typically doing so during the first epoch helps training. Try increasing this value if the loss does not decrease.#\n",
        ",\"lr\":0.0005 #help=Learning rate at the end of linear warmup (highest LR used during training). The learning rate is linearly scaled with the batch size, and specified here for a reference batch size of 256.#\n",
        ",\"warmup_epochs\":10 #help=\"Number of epochs for the linear learning-rate warm up.#\n",
        ",\"min_lr\":1e-6 #help=Target LR at the end of optimization. We use a cosine LR schedule with linear warmup.#\n",
        ",\"optimizer\":'adamw' #help=Type of optimizer. We recommend using adamw with ViTs.#\n",
        ",\"drop_path_rate\":0.1 #help=\"stochastic depth rate#\n",
        "\n",
        "# Multi-crop parameters\n",
        ",\"global_crops_scale\":(0.4, 1.) #help=Scale range of the cropped image before resizing, relatively to the origin image. Used for large global view cropping. When disabling multi-crop (--local_crops_number 0), we recommand using a wider range of scale (\"--global_crops_scale 0.14 1.\" for example)#\n",
        ",\"local_crops_number\":8 #help=Number of small local views to generate. Set this parameter to 0 to disable multi-crop training. When disabling multi-crop we recommend to use \"--global_crops_scale 0.14 1.\" #\n",
        ",\"local_crops_scale\":(0.05,0.4) #help=Scale range of the cropped image before resizing, relatively to the origin image. Used for small local view cropping of multi-crop.#\n",
        "# Misc\n",
        ",\"data_path\":\"/content/drive/MyDrive/Final Project/dataset/test/\" #help=Please specify path to the ImageNet training data.#\n",
        ",\"output_dir\":\".\" #help\":Path to save logs and checkpoints.#\n",
        ",\"saveckp_freq\":20 #help=Save checkpoint every x epochs.#\n",
        ",\"seed\":0 #help=Random seed.#\n",
        ",\"num_workers\":10 #help=Number of data loading workers per GPU.#\n",
        ",\"dist_url\":\"env://\" #help=\"\"\"url used to set up distributed training; see https://pytorch.org/docs/stable/distributed.html\"\"\")\n",
        ",\"local_rank\":0 #help=\"Please ignore and do not set this argument.\")\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thliMM-diXUi"
      },
      "source": [
        "# Loading and Visualising Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6oSiEBpim63"
      },
      "source": [
        "## Loading Mnist "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTcEnwgCiceS",
        "outputId": "1681998f-4de8-44b6-f300-c31809e6d3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_JBl7VPihLy"
      },
      "source": [
        "## Visualising Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "aPTw4K24ilxK",
        "outputId": "0717d235-2916-49a8-bcd4-1e7428103dc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8JDmceVjCeq"
      },
      "source": [
        "##Dataset Loader Mnist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJmj9Jwdi2FT",
        "outputId": "f6f848f9-8039-41a0-881c-f2595bd2eab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------Loaded Mnist Dataset------|\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n",
            "|------Test Dataset Generated------|\n",
            "Total Labels 10 Time to load: 0.30873942375183105 seconds\n"
          ]
        }
      ],
      "source": [
        "class MnistDatasetTrainClass(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "      self.label =[]\n",
        "      self.images = []\n",
        "      self.label_dict = {}\n",
        "      start_time = time.time()\n",
        "      (self.trainX, self.trainy), (self.testX, self.testy) = mnist.load_data()\n",
        "      self.width,self.height  = width,height\n",
        "      print(\"|------Loaded Mnist Dataset------|\")\n",
        "      print('Train: X=%s, y=%s' % (self.trainX.shape, self.trainy.shape))\n",
        "      print('Test: X=%s, y=%s' % (self.testX.shape, self.testy.shape))\n",
        "      for i,label in enumerate(self.trainy):\n",
        "        if label in self.label_dict:\n",
        "          self.label_dict[label].append(i) \n",
        "        else: \n",
        "          self.label_dict[label] = [i]\n",
        "          \n",
        "      print(\"|------Test Dataset Generated------|\")\n",
        "      print(f\"Total Labels {len(self.label_dict)} Time to load: {time.time() - start_time} seconds\")\n",
        "\n",
        "    def detach_cropped_area(self,im):\n",
        "        # image = Image.fromarray(im)\n",
        "        # newimage = image.resize((self.width,self.height))\n",
        "        # scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        # scaler.fit(newimage)\n",
        "        # newimage = scaler.transform(newimage)\n",
        "        #numpy_array = np.asarray(cropped_img)\n",
        "        # if debug == True && False:\n",
        "        #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "        # print(newimage)\n",
        "        #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "        # if debug == True:\n",
        "        #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "        #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "        #   pyplot.show()\n",
        "\n",
        "        #return torch.tensor(np.array(newimage), dtype=torch.float32)\n",
        "        return torch.tensor(np.array(im), dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        clas = np.random.randint(0,10)\n",
        "        idx_1,idx_2 = np.random.randint(0,len(self.label_dict[clas]),2) \n",
        "        img_1_idx,img_2_idx = self.label_dict[clas][idx_1],self.label_dict[clas][idx_2]\n",
        "        img1 = self.detach_cropped_area(self.trainX[img_1_idx]).reshape(1,self.width,self.height)\n",
        "        img2 = self.detach_cropped_area(self.trainX[img_2_idx]).reshape(1,self.width,self.height)\n",
        "        y1 = torch.tensor(np.ones(1,dtype=np.float32),dtype=torch.float32)\n",
        "        \n",
        "        clas2 = np.random.randint(0,10)\n",
        "        while clas2 == clas:\n",
        "            clas2 = np.random.randint(0,10)\n",
        "\n",
        "        if clas2 == clas:\n",
        "          print(\"Same  positive and negative labels detected\")\n",
        "        idx_3 = np.random.randint(0,len(self.label_dict[clas])) \n",
        "        idx_4 = np.random.randint(0,len(self.label_dict[clas2])) \n",
        "        img_3_idx,img_4_idx = self.label_dict[clas][idx_3],self.label_dict[clas2][idx_4]\n",
        "        img3 = self.detach_cropped_area(self.trainX[img_3_idx]).reshape(1,self.width,self.height)\n",
        "        img4 = self.detach_cropped_area(self.trainX[img_4_idx]).reshape(1,self.width,self.height)\n",
        "        y2 = torch.tensor(np.zeros(1,dtype=np.float32),dtype=torch.float32)\n",
        "        \n",
        "        # im = Image.fromarray(self.images[idx])\n",
        "        # label = self.label[idx]\n",
        "        # input_1 = torch.tensor(detach_cropped_area_test(im,(0, 10, 52, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # label_1 = torch.tensor(detach_cropped_area_test(im,(0, 52, 52, 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # input_2 = torch.tensor(detach_cropped_area_test(im,(85, 10, 130, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height )\n",
        "        # label_2 = torch.tensor(detach_cropped_area_test(im,(85, 52, 130 , 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # query = torch.tensor(detach_cropped_area_test(im,(180, 35, 230 , 60)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "\n",
        "\n",
        "        return  img1, img2, y1, img3, img4, y2\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return len(self.label_dict[0])\n",
        "MnistDatasetTrain = MnistDatasetTrainClass(10000,width=28,height=28)\n",
        "# train_dataloader_mnist = DataLoader(MnistDatasetTrain, shuffle=True, batch_size= 4,num_workers=1)\n",
        "# for count_idx,data in enumerate(train_dataloader_mnist):\n",
        "#   img1, img2, y1, img3, img4, y2 = data\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"------------img1-------------\")\n",
        "#   print(img1.shape)\n",
        "#   im = pyplot.imshow(img1[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img2-------------\")\n",
        "#   im = pyplot.imshow(img2[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img3-------------\")\n",
        "#   im = pyplot.imshow(img3[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img4-------------\")\n",
        "#   im = pyplot.imshow(img4[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------y1-------------\")\n",
        "#   print(y1)\n",
        "#   print(\"------------y2-------------\")\n",
        "#   print(y2)\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEx7y5b4truF",
        "outputId": "e50b6c11-6937-4af4-e767-75acf9ba305d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------Loaded Mnist Dataset------|\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n",
            "|------Test Dataset Generated------|\n",
            "Total Labels 10 Time to load: 0.29763245582580566 seconds\n"
          ]
        }
      ],
      "source": [
        "class MnistDatasetTestClass(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "      self.label =[]\n",
        "      self.images = []\n",
        "      self.label_dict = {}\n",
        "      start_time = time.time()\n",
        "      (self.trainX, self.trainy), (self.testX, self.testy) = mnist.load_data()\n",
        "      self.width,self.height  = width,height\n",
        "      print(\"|------Loaded Mnist Dataset------|\")\n",
        "      print('Train: X=%s, y=%s' % (self.trainX.shape, self.trainy.shape))\n",
        "      print('Test: X=%s, y=%s' % (self.testX.shape, self.testy.shape))\n",
        "      for i,label in enumerate(self.testy):\n",
        "        if label in self.label_dict:\n",
        "          self.label_dict[label].append(i) \n",
        "        else: \n",
        "          self.label_dict[label] = [i]\n",
        "          \n",
        "      print(\"|------Test Dataset Generated------|\")\n",
        "      print(f\"Total Labels {len(self.label_dict)} Time to load: {time.time() - start_time} seconds\")\n",
        "\n",
        "    def detach_cropped_area(self,im):\n",
        "        # image = Image.fromarray(im)\n",
        "        # newimage = image.resize((self.width,self.height))\n",
        "        # scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        # scaler.fit(newimage)\n",
        "        # newimage = scaler.transform(newimage)\n",
        "        #numpy_array = np.asarray(cropped_img)\n",
        "        # if debug == True && False:\n",
        "        #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "        # print(newimage)\n",
        "        #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "        # if debug == True:\n",
        "        #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "        #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "        #   pyplot.show()\n",
        "\n",
        "        #return torch.tensor(np.array(newimage), dtype=torch.float32)\n",
        "        return torch.tensor(np.array(im), dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        clas = np.random.randint(0,10)\n",
        "        idx_1,idx_2 = np.random.randint(0,len(self.label_dict[clas]),2) \n",
        "        img_1_idx,img_2_idx = self.label_dict[clas][idx_1],self.label_dict[clas][idx_2]\n",
        "        img1 = self.detach_cropped_area(self.testX[img_1_idx]).reshape(1,self.width,self.height)\n",
        "        img2 = self.detach_cropped_area(self.testX[img_2_idx]).reshape(1,self.width,self.height)\n",
        "        y1 = torch.tensor(np.ones(1,dtype=np.float32),dtype=torch.float32)\n",
        "        \n",
        "        clas2 = np.random.randint(0,10)\n",
        "        while clas2 == clas:\n",
        "            clas2 = np.random.randint(0,10)\n",
        "\n",
        "        if clas2 == clas:\n",
        "          print(\"Same  positive and negative labels detected\")\n",
        "        idx_3 = np.random.randint(0,len(self.label_dict[clas])) \n",
        "        idx_4 = np.random.randint(0,len(self.label_dict[clas2])) \n",
        "        img_3_idx,img_4_idx = self.label_dict[clas][idx_3],self.label_dict[clas2][idx_4]\n",
        "        img3 = self.detach_cropped_area(self.testX[img_3_idx]).reshape(1,self.width,self.height)\n",
        "        img4 = self.detach_cropped_area(self.testX[img_4_idx]).reshape(1,self.width,self.height)\n",
        "        y2 = torch.tensor(np.zeros(1,dtype=np.float32),dtype=torch.float32)\n",
        "        \n",
        "        # im = Image.fromarray(self.images[idx])\n",
        "        # label = self.label[idx]\n",
        "        # input_1 = torch.tensor(detach_cropped_area_test(im,(0, 10, 52, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # label_1 = torch.tensor(detach_cropped_area_test(im,(0, 52, 52, 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # input_2 = torch.tensor(detach_cropped_area_test(im,(85, 10, 130, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height )\n",
        "        # label_2 = torch.tensor(detach_cropped_area_test(im,(85, 52, 130 , 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        # query = torch.tensor(detach_cropped_area_test(im,(180, 35, 230 , 60)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "\n",
        "\n",
        "        return  img1, img2, y1, img3, img4, y2\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return 1000\n",
        "MnistDatasetTest = MnistDatasetTestClass(1000,width=28,height=28)\n",
        "# train_dataloader_mnist = DataLoader(MnistDatasetTrain, shuffle=True, batch_size= 4,num_workers=1)\n",
        "# for count_idx,data in enumerate(train_dataloader_mnist):\n",
        "#   img1, img2, y1, img3, img4, y2 = data\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"------------img1-------------\")\n",
        "#   print(img1.shape)\n",
        "#   im = pyplot.imshow(img1[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img2-------------\")\n",
        "#   im = pyplot.imshow(img2[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img3-------------\")\n",
        "#   im = pyplot.imshow(img3[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img4-------------\")\n",
        "#   im = pyplot.imshow(img4[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------y1-------------\")\n",
        "#   print(y1)\n",
        "#   print(\"------------y2-------------\")\n",
        "#   print(y2)\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkOChwplUupz"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAbDBIn2U9ds"
      },
      "outputs": [],
      "source": [
        "\n",
        "window_width, window_height = 250, 80\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "class CustomEnv(gym.Env):\n",
        "    def __init__(self,env_config={},n_objects=2,debug=False):\n",
        "      self.n_objects = n_objects\n",
        "      self.corpus = {\n",
        "      0 : 'zero',\n",
        "      1 : 'one',\n",
        "      2 : 'two',\n",
        "      3 : 'three',\n",
        "      4 : 'four',\n",
        "      5 : 'five',\n",
        "      6 : 'six',\n",
        "      7 : 'seven',\n",
        "      8 : 'eight',\n",
        "      9 : 'nine', \n",
        "      }\n",
        "      self.sprites_to_train = 2\n",
        "      self.action_space = gym.spaces.Discrete(4)\n",
        "      self.observation_space = gym.spaces.Box(\n",
        "      low=0, high=255, shape=(window_height,window_width), dtype=np.float16)\n",
        "      (self.trainx, self.trainy), (self.testx, self.testy) = self.loadDataset('mnist')\n",
        "      self.classes = set(trainy)\n",
        "      self.classes_len = len(self.classes)\n",
        "      self.debug = debug\n",
        "      # summarize loaded dataset\n",
        "      if self.debug == True:\n",
        "        print(\"|------------------ Dataset -----------------|\")\n",
        "        print(f'Train: X={self.trainx.shape}, y={self.trainy.shape}')\n",
        "        print(f'Test: X={self.testx.shape}, y={self.testy.shape}')\n",
        "        print(f'Classes: Unique={self.classes}, len={self.classes_len}')\n",
        "        print(\"|--------------------------------------------|\")\n",
        "      self.reset()\n",
        "    def loadDataset(self,dataset_name):\n",
        "      if dataset_name == 'mnist':\n",
        "        return mnist.load_data()\n",
        "\n",
        "    def generate_unique_random(self,prev,corpus):\n",
        "        \n",
        "        input = random.choice(list(corpus.keys()))\n",
        "        if (input in prev):\n",
        "          while (input in prev):\n",
        "            input = random.choice(list(corpus.keys()))\n",
        "        return input\n",
        "\n",
        "    def get_image_from_label(self,data,label):\n",
        "        #get all indexes for given label from data and select an image as random \n",
        "        indexes = []\n",
        "        for i in range(len(data[1])):\n",
        "          if label == data[1][i]:\n",
        "            indexes.append(i)        \n",
        "        image_pixel= np.array(data[0][random.choice(indexes)]).T\n",
        "        #img = Image.fromarray(image_pixel)\n",
        "        return image_pixel\n",
        "\n",
        "    def reset(self):\n",
        "        pygame.init()\n",
        "        pygame.font.init()\n",
        "        self.window = pygame.display.set_mode((window_width, window_height))\n",
        "        #self.myfont = pygame.font.SysFont(random.choice(sys_font_list), 15)\n",
        "        self.myfont = pygame.font.SysFont(\"Arial\", 15)\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.window.fill(0)\n",
        "        self.objects = []\n",
        "        self.instruction_pane_width = 120\n",
        "        self.instruction_pane_height = window_height\n",
        "        self.instruction_pane_x = window_width - self.instruction_pane_width\n",
        "        self.instruction_pane_y = 0\n",
        "        #Create agent\n",
        "        \n",
        "        self.inputs_choosen = []\n",
        "        self.init_sprite(\"agent_0\",0,0,15,15,path=\"./drive/MyDrive/Final Project/assets/mouse.png\")  \n",
        "        for i in range(self.sprites_to_train):\n",
        "          #ensure same input is not choosen again\n",
        "          input_label = self.generate_unique_random(self.inputs_choosen,self.corpus)\n",
        "          sprite_iamge = self.get_image_from_label((self.trainx,self.trainy),input_label)\n",
        "          #display inputs chosen\n",
        "          # pyplot.imshow(sprite_iamge, cmap=pyplot.get_cmap('gray'))\n",
        "          # pyplot.show()\n",
        "          self.init_sprite(\"sprite_\"+str(i),(i*45)+10,10,42,42,label_class = input_label,image = sprite_iamge,label=input_label,label_text=self.corpus[input_label],augmentation=True)\n",
        "          self.inputs_choosen.append(input_label)\n",
        "        if self.debug == True:\n",
        "          print(f\"Env Objects: {self.objects}\")\n",
        "        self.selected_instruction = random.choice(self.inputs_choosen)\n",
        "        if self.debug == True:\n",
        "          print(f\"self.inputs_choosen: {self.inputs_choosen} self.selected_instruction {self.selected_instruction}\")\n",
        "        self.done = True\n",
        "        self.render_screen()\n",
        "        return self.observation_to_img(),self.inputs_choosen,self.selected_instruction\n",
        "\n",
        "    def random_augmentation(self,sprite):\n",
        "        #implement code for random augmentation here\n",
        "        return sprite\n",
        "\n",
        "    def init_sprite(self,id,x,y,width,height,label_class=None,path=None,image=None,label = None,label_text = None,augmentation=False):\n",
        "        if path != None:\n",
        "          sprite = pygame.transform.scale(pygame.image.load(path).convert_alpha(), (width,height)) \n",
        "        else:\n",
        "          sprite = pygame.transform.scale(pygame.surfarray.make_surface(image), (width,height))\n",
        "        if augmentation == True:\n",
        "          sprite = self.random_augmentation(sprite) \n",
        "        color = (255,255,255)\n",
        "        \n",
        "        if label == None:\n",
        "          self.objects.append(\n",
        "            {\n",
        "                \"id\" : id,\n",
        "                \"sprite\" : sprite,\n",
        "                \"collision_box\" : sprite.get_rect(x=(window_width - self.instruction_pane_width)/2, y=(window_height)/2),\n",
        "                \"color\" : color,\n",
        "                \"path\" : path,\n",
        "            }\n",
        "          )\n",
        "        else:\n",
        "          if id == \"sprite_0\":\n",
        "            self.objects.append(\n",
        "                {\n",
        "                    \"id\" : id,\n",
        "                    \"sprite\" : sprite,\n",
        "                    \"collision_box\" : sprite.get_rect(x=0, y=y),\n",
        "                    \"label_text\" : label_text,\n",
        "                    \"label\" : self.myfont.render(label_text, False, color),\n",
        "                    \"label_position\" : (x,y+height+5),\n",
        "                    \"label_class\": label_class,\n",
        "                    \"color\" : color,\n",
        "                    \"path\" : path,\n",
        "                }\n",
        "            )\n",
        "          if id == \"sprite_1\":\n",
        "            self.objects.append(\n",
        "                {\n",
        "                    \"id\" : id,\n",
        "                    \"sprite\" : sprite,\n",
        "                    \"collision_box\" : sprite.get_rect(x=window_width - self.instruction_pane_width-width, y=y),\n",
        "                    \"label_text\" : label_text,\n",
        "                    \"label\" : self.myfont.render(label_text, False, color),\n",
        "                    \"label_position\" : (window_width - self.instruction_pane_width-width,y+height+5),\n",
        "                    \"label_class\": label_class,\n",
        "                    \"color\" : color,                 \n",
        "                    \"path\" : path,\n",
        "                }\n",
        "            )\n",
        "    def check_agent_collision(self):\n",
        "      sprite_collision_boxes = []\n",
        "      for i in range(len(self.objects)):\n",
        "        if self.objects[i][\"id\"] == \"agent_0\":\n",
        "          agent_collision_box = self.objects[i][\"collision_box\"]\n",
        "        else:\n",
        "          sprite_collision_boxes.append(self.objects[i][\"collision_box\"])\n",
        "      for i in range(len(sprite_collision_boxes)):\n",
        "        if sprite_collision_boxes[i].colliderect(agent_collision_box):\n",
        "          #print(f\"Collision Detected between agent_0 and sprite_{i}\")\n",
        "          return True,\"sprite_\"+str(i)\n",
        "      return False,None\n",
        "    def move_sprite(self,id,x,y):\n",
        "      for i in range(len(self.objects)):\n",
        "        if self.objects[i][\"id\"] == id:\n",
        "          collision_box = self.objects[i][\"collision_box\"]\n",
        "          \n",
        "          self.objects[i][\"collision_box\"] = self.objects[i][\"sprite\"].get_rect(x=collision_box.x+x, y=collision_box.y+y)\n",
        "          collision_box = self.objects[i][\"collision_box\"]\n",
        "\n",
        "        if collision_box.x >= window_width - self.instruction_pane_width or collision_box.x < 0 or collision_box.y >= window_height or collision_box.y < 0:\n",
        "          self.done = True\n",
        "    def step(self, action=np.zeros((4),dtype=np.int32)):\n",
        "        if action == 0:  # Right\n",
        "          self.move_sprite(\"agent_0\",1,0)\n",
        "        if action == 1:  # Left\n",
        "          self.move_sprite(\"agent_0\",-1,0)\n",
        "        if action == 2:  # Up\n",
        "          self.move_sprite(\"agent_0\",0,-1)\n",
        "        if action == 3:  # Down\n",
        "          self.move_sprite(\"agent_0\",0,1)\n",
        "        collision,id = self.check_agent_collision() \n",
        "        if collision:\n",
        "          for i in range(len(self.objects)):\n",
        "            if self.objects[i][\"id\"] == id and self.objects[i][\"label_class\"] == self.selected_instruction:\n",
        "              observation, reward, done, info = self.observation_to_img(), 100, self.done, {}\n",
        "              self.reset()\n",
        "              break;\n",
        "            else:\n",
        "              observation, reward, done, info = self.observation_to_img(), 0, self.done, {}\n",
        "\n",
        "        else:\n",
        "          observation, reward, done, info = self.observation_to_img(), 0, self.done, {}\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def observation_to_img(self):\n",
        "        pygame.display.update()\n",
        "        #convert image so it can be displayed in OpenCV\n",
        "        view = pygame.surfarray.array3d(self.window)\n",
        "        #  convert from (width, height, channel) to (height, width, channel)\n",
        "        view = view.transpose([1, 0, 2])\n",
        "        #  convert from rgb to bgr\n",
        "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2GRAY)\n",
        "        return img_bgr\n",
        "\n",
        "    def render_instructions(self):\n",
        "        pygame.draw.rect(self.window, (0, 0,0), (self.instruction_pane_x,self.instruction_pane_y,self.instruction_pane_width,self.instruction_pane_height))\n",
        "        title = self.myfont.render('Instructions:', False, (255, 255, 255))\n",
        "        self.window.blit(title,(self.instruction_pane_x+20,20))\n",
        "        instruction_1 = self.myfont.render(f'Find {self.corpus[self.selected_instruction]}', False, (255, 255, 255))\n",
        "        self.window.blit(instruction_1,(self.instruction_pane_x+20,40))\n",
        "\n",
        "    def render_screen(self):\n",
        "        self.window.fill(0)\n",
        "        # draw orientation\n",
        "        # p1 = (self.x - 10 * np.cos(self.ang),self.y + 10 * np.sin(self.ang))\n",
        "        # p2 = (self.x + 15 * np.cos(self.ang),self.y - 15 * np.sin(self.ang))\n",
        "        # pygame.draw.line(self.window,(0,100,100),p1,p2,2)\n",
        "        self.render_instructions()\n",
        "        for elem in self.objects:\n",
        "          self.window.blit(elem[\"sprite\"], elem[\"collision_box\"])\n",
        "          if \"label\" in elem.keys():\n",
        "            self.window.blit(elem[\"label\"],elem[\"label_position\"])\n",
        "        #Display image, clear cell every 0.5 seconds\n",
        "        #cv2_imshow(self.observation_to_img())\n",
        "    def render(self):\n",
        "        self.render_screen()\n",
        "        time.sleep(0.1)\n",
        "        output.clear()\n",
        "\n",
        "environment = CustomEnv()\n",
        "rewards = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIu9DZryoWMI"
      },
      "source": [
        "#Graph Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1RD_oAooYy2"
      },
      "source": [
        "## Util"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mXRHqe4oaO-"
      },
      "source": [
        "###Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Oo6_PPTnJLi"
      },
      "outputs": [],
      "source": [
        "# Defining a Class\n",
        "class GraphVisualization:\n",
        "   \n",
        "    def __init__(self,graph):\n",
        "          \n",
        "        # visual is a list which stores all \n",
        "        # the set of edges that constitutes a\n",
        "        # graph\n",
        "        self.visual = graph['edge_index'].numpy().reshape(-1,2)\n",
        "        self.labels = graph['x']\n",
        "        self.label_dict = {}\n",
        "        for idx,label in enumerate(self.labels):\n",
        "          self.label_dict[idx] = str(idx)#+\" : \" + str(label.numpy()[0])\n",
        "          \n",
        "    # In visualize function G is an object of\n",
        "    # class Graph given by networkx G.add_edges_from(visual)\n",
        "    # creates a graph with a given list\n",
        "    # nx.draw_networkx(G) - plots the graph\n",
        "    # plt.show() - displays the graph\n",
        "    def visualize(self):\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(self.visual)\n",
        "        nx.draw_networkx(G, node_size=500)\n",
        "        plt.show()\n",
        "#Driver Code\n",
        "#Creating a basic graph using Pytorch Geometric\n",
        "\n",
        "# edge_index = torch.tensor([[0, 1, 1, 2],\n",
        "#                            [1, 0, 2, 1]], dtype=torch.long)\n",
        "# x = torch.tensor([[-1], [0], [1]], dtype=int)\n",
        "\n",
        "# data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# G = GraphVisualization(data)\n",
        "# G.visualize()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-1ey0rnEg36"
      },
      "source": [
        "## Segraph Create Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SgD7BScEiVq"
      },
      "outputs": [],
      "source": [
        "def create_graph(grid):\n",
        "    \"\"\"\n",
        "    This function creates a graph of vertices and edges from segments returned by SLIC.\n",
        "    :param array grid: A grid of segments as returned by the slic function defined in skimage library\n",
        "    :return: A graph as [vertices, edges]\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "    except ImportError:\n",
        "        print(\n",
        "            \"NumPY is not installed. segraph needs NumPY to function. Please use 'pip install numpy' to install numpy.\")\n",
        "        exit(0)\n",
        "    #print(\"Creating a graph using segmented grid..\")\n",
        "    # get an array of unique labels\n",
        "    try:\n",
        "        vertices = np.unique(grid)\n",
        "\n",
        "        # get number of vertices\n",
        "        num_vertices = len(vertices)\n",
        "\n",
        "        # map these unique labels to [1,...,N], where N is the number of labels (vertices)\n",
        "        mapping = dict(zip(vertices, np.arange(num_vertices)))\n",
        "        mapped_grid = np.array([mapping[x] for x in grid.flat]).reshape(grid.shape)\n",
        "\n",
        "        # create edges, going left to right and top to bottom\n",
        "        l2r = np.c_[mapped_grid[:, :-1].ravel(), mapped_grid[:, 1:].ravel()]\n",
        "        t2b = np.c_[mapped_grid[:-1, :].ravel(), mapped_grid[1:, :].ravel()]\n",
        "\n",
        "        # stack for entire graph\n",
        "        edges = np.vstack([l2r, t2b])\n",
        "        edges = edges[edges[:, 0] != edges[:, 1], :]\n",
        "        edges = np.sort(edges, axis=1)\n",
        "\n",
        "        # create a edge map, a hashmap\n",
        "        edge_map = edges[:, 0] + num_vertices * edges[:, 1]\n",
        "\n",
        "        # filter unique connections as edges\n",
        "        edges = np.unique(edge_map)\n",
        "\n",
        "        # reverse map and form edges as pairs\n",
        "        edges = [[vertices[edge % num_vertices],\n",
        "                  vertices[edge // num_vertices]] for edge in edges]\n",
        "    except:\n",
        "        print(\"Invalid argument supplied !\")\n",
        "        return None\n",
        "\n",
        "    return vertices, edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLRIrKV2owdp"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VBLhy5royiH"
      },
      "source": [
        "### Mnist Train Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr5Dw1FLv7WW"
      },
      "outputs": [],
      "source": [
        "class MnistGraph(Dataset):\n",
        "\n",
        "    def __init__(self,num_of_samples):\n",
        "        self.num_of_samples = num_of_samples\n",
        "        (self.trainX, self.trainy), (self.testX, self.testy) = mnist.load_data()\n",
        "        self.trainX=self.trainX[:self.num_of_samples]\n",
        "        self.trainy=self.trainy[:self.num_of_samples]\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        ip_image = Image.fromarray(self.trainX[idx]).resize((28,28))\n",
        "        segments = slic(ip_image, n_segments=75, sigma=5)\n",
        "        vertices, edges = create_graph(segments)\n",
        "        # fig = plt.figure(\"Superpixels\")\n",
        "        # ax = fig.add_subplot(1, 1, 1)\n",
        "        # ax.imshow(mark_boundaries(ip_image, segments))\n",
        "        # plt.axis(\"off\")\n",
        "        # plt.show()\n",
        "        # random_indexes = random.sample(list(np.arange(len(self.trainy))), self.samples_per_graph)\n",
        "        # trainX=[]\n",
        "        # trainy=[]\n",
        "        # for i in random_indexes:\n",
        "        #   trainX.append(self.trainX[i])\n",
        "        #   trainy.append(self.trainy[i])\n",
        "        # dataset_graph =  {}\n",
        "        # #print(np.array(trainX).shape)\n",
        "\n",
        "        x = torch.tensor(vertices, dtype=torch.float32 )\n",
        "        y = self.trainy[idx]#F.one_hot(torch.tensor(trainy, dtype=torch.int64), num_classes=10).double()#torch.tensor(trainy, dtype=torch.int64)#\n",
        "        edge_list = torch.tensor(edges, dtype=torch.int64).reshape(2,-1)\n",
        "        data = Data(x=x, edge_index=edge_list,y=y)\n",
        "        return  data\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "\n",
        "        return self.num_of_samples\n",
        "\n",
        "mnistGraph = MnistGraph(num_of_samples = 20000)\n",
        "#Driver Code to seee one of the graphs\n",
        "# loader = GraphDataLoader(mnistGraph, batch_size=4,num_workers=1)\n",
        "# for batch in loader:\n",
        "#   print(f\"Batch {batch}\")\n",
        "#   print(f\"batch.shape {np.array(batch).shape}\")\n",
        "#   print(f\"Graph 0 {batch[0]}\")\n",
        "#   print(f\"Node Data: {batch[0].x.shape}\")\n",
        "#   #print(f\"Node Label: {batch[0].y[0]} type:{batch[0].y[0].dtype}\")\n",
        "#   #print(batch[0].x[0][0].dtype)\n",
        "#   #pyplot.imshow(batch[0].x[0].reshape(81,81), cmap=pyplot.get_cmap('gray'))\n",
        "#   #pyplot.show()\n",
        "#   G = GraphVisualization(batch[0])\n",
        "#   G.visualize()\n",
        "#   break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNR5gMB0_HRl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn_p-t7xAWaV"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.utils import to_networkx\n",
        "# G = to_networkx(dataset[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbXmSNf3U_br"
      },
      "outputs": [],
      "source": [
        "# ##Driver Code to seee one of the graphs\n",
        "# loader = GraphDataLoader(mnistGraph, batch_size=4,num_workers=1)\n",
        "# for batch in loader:\n",
        "#   print(f\"Batch {batch}\")\n",
        "#   print(f\"batch.shape {np.array(batch).shape}\")\n",
        "#   print(f\"Graph 0 {np.array(batch[0])}\")\n",
        "#   print(f\"Node Data: {batch[0].x.shape}\")\n",
        "#   print(f\"Node Label: {batch[0].y[0]} type:{batch[0].y[0].dtype}\")\n",
        "#   print(batch[0].x[0][0].dtype)\n",
        "#   pyplot.imshow(batch[0].x[0].reshape(81,81), cmap=pyplot.get_cmap('gray'))\n",
        "#   pyplot.show()\n",
        "#   G = GraphVisualization(batch[0])\n",
        "#   G.visualize()\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNxY-aVSsAXG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKoq9uDppjsP"
      },
      "outputs": [],
      "source": [
        "# class GCN(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "        \n",
        "#         self.conv1 = GCNConv(784, 64)#num_node_features\n",
        "#         self.conv2 = GCNConv(64, 4)\n",
        "#         self.conv3 = GCNConv(4, 10)\n",
        "#         #self.conv3 = GCNConv(2, 10)\n",
        "#         # self.conv4 = GCNConv(8, 16)\n",
        "#         # self.conv5 = GCNConv(16, 10)\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         x = F.dropout(x, training=self.training)\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         x = F.relu(x)\n",
        "#         #x = F.dropout(x, training=self.training)\n",
        "#         x = self.conv3(x, edge_index)\n",
        "#         # x = F.relu(x)\n",
        "#         # x = F.dropout(x, training=self.training)\n",
        "#         # x = self.conv4(x, edge_index)\n",
        "#         # x = F.relu(x)\n",
        "#         # x = F.dropout(x, training=self.training)\n",
        "#         # x = self.conv5(x, edge_index)\n",
        "#         return F.log_softmax(x, dim=1)\n",
        "class GNNEncoder(torch.nn.module):\n",
        "    def __init__(self):\n",
        "        super(GNNEncoder, self).__init__()\n",
        "    def forward(self, \n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAT, self).__init__()\n",
        "        self.hid = 8\n",
        "        self.in_head = 8\n",
        "        self.out_head = 1\n",
        "        \n",
        "        \n",
        "        self.conv1 = GATConv(1, self.hid, heads=self.in_head, dropout=0.6)\n",
        "        self.conv2 = GATConv(self.hid*self.in_head, self.hid,heads=self.in_head)\n",
        "        self.conv3 = GATConv(self.hid*self.in_head, 128, concat=False,\n",
        "                             heads=self.out_head)\n",
        "        self.lin = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index,batch = data.x.reshape(-1,1), data.edge_index,data.batch\n",
        "                \n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XWDDtZKink"
      },
      "source": [
        "## Validation GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zgZzjM6Kkg7"
      },
      "outputs": [],
      "source": [
        "def validationGNN(trained_model,batch_size):\n",
        "  train_loader = GraphDataLoader(mnistGraph, batch_size=batch_size,num_workers=1)\n",
        "  with torch.no_grad():\n",
        "    model = trained_model\n",
        "    model.eval()\n",
        "    t_label = []\n",
        "    p_labels = []\n",
        "    count_correct = 0\n",
        "    total_len = 0\n",
        "    for itr,data in enumerate(train_loader):\n",
        "        pred = model(data.cuda())\n",
        "        # print(pred.argmax(dim=1))\n",
        "        # print(data.y)\n",
        "        count_correct += (torch.argmax(pred,dim=1) == torch.tensor(data.y).cuda() ).sum()\n",
        "        total_len += int(len(pred))\n",
        "    acc = int(count_correct) / int(total_len)\n",
        "    print(f'|------------Accuracy: {acc:.4f} Total Correct Predicted{count_correct} out of {total_len}------------|')\n",
        "    return count_correct\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RktQXLb2sIcI"
      },
      "source": [
        "## Train One Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YqilOIsPpX"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import MNISTSuperpixels\n",
        "         \n",
        "  #print(f\"Validation accuracy: {classification_report(t_label,p_labels, target_names=['class 1'])}\")\n",
        "\n",
        "  \n",
        "def train_gnn(model,batch_size, num_epochs, Criterion,Optimizer):\n",
        "    train_losses = []\n",
        "    train_loader = GraphDataLoader(mnistGraph, batch_size=batch_size,num_workers=1)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        count_correct = 0\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        start_time = time.time()\n",
        "        count = 0\n",
        "        for count_idx,data in enumerate(train_loader):\n",
        "          Optimizer.zero_grad()\n",
        "          #print(data)\n",
        "          out = model(data.cuda())\n",
        "          \n",
        "          # print(out.shape)\n",
        "          # print(out[0])\n",
        "          # print(torch.tensor(data.y).shape)\n",
        "          # print(data.y[0])\n",
        "          loss = Criterion(out, torch.tensor(data.y).cuda())\n",
        "          loss.backward()\n",
        "          Optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          # print(\"Predicted\")\n",
        "          # print(torch.argmax(out,dim=1).reshape(-1,1))\n",
        "          # print(\"Target\")\n",
        "          # print(torch.tensor(data.y).reshape(-1,1))\n",
        "          # print((torch.argmax(out,dim=1) == torch.tensor(data.y).cuda() ))\n",
        "          count_correct += (torch.argmax(out,dim=1) == torch.tensor(data.y).cuda() ).sum()\n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'[Train]Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss} Correct Prediction: {count_correct} Accuracy:{count_correct / 60000} Time: {time.time() - start_time}')\n",
        "        #if (epoch+1) % 100 == 0:\n",
        "          #validationGNN(model,1)\n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/gnn.pth\")\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj6s4pAJsLUn"
      },
      "source": [
        "## Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGXUy3U-sHyv"
      },
      "outputs": [],
      "source": [
        "# model = GAT().cuda()#GCN().cuda()\n",
        "# pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/gnn.pth\"\n",
        "# # if os.path.isfile(pretrained_weight_path):\n",
        "# model.load_state_dict(torch.load(pretrained_weight_path))\n",
        "# params = model.parameters()\n",
        "# Criterion = F.nll_loss\n",
        "# Optimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=5e-4)\n",
        "# train_gnn(model,16, 1000, Criterion,Optimizer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IZmcfL_ZmXkL",
        "outputId": "4964d1f4-d3cb-42f1-9a62-691251fa2e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-15 00:27:30,781]\u001b[0m A new study created in memory with name: no-name-04a3dd52-6379-4ab5-9367-3bcb62b4490f\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 191.36692668497562 Correct Prediction: 1974 Accuracy:0.03290000185370445 Time: 45.21206307411194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 237.29851457476616 Correct Prediction: 1991 Accuracy:0.03318333253264427 Time: 45.0516722202301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 182.4291785210371 Correct Prediction: 2024 Accuracy:0.03373333439230919 Time: 45.151583433151245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:32:05,568]\u001b[0m Trial 0 finished with value: 2281.0 and parameters: {'lr': 0.026169181236368116}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 184.0369373857975 Correct Prediction: 2068 Accuracy:0.034466665238142014 Time: 44.911306381225586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.7905713915825 Correct Prediction: 2132 Accuracy:0.03553333505988121 Time: 45.182061195373535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.45218934118748 Correct Prediction: 2093 Accuracy:0.03488333523273468 Time: 44.96896147727966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:36:42,500]\u001b[0m Trial 1 finished with value: 2014.0 and parameters: {'lr': 0.00011819632005158924}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1007 Total Correct Predicted2014 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.9721607118845 Correct Prediction: 2013 Accuracy:0.03355000168085098 Time: 45.200538635253906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.0694142729044 Correct Prediction: 2145 Accuracy:0.035750001668930054 Time: 45.36315369606018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.90103617310524 Correct Prediction: 2220 Accuracy:0.03700000047683716 Time: 45.42331075668335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:41:19,020]\u001b[0m Trial 2 finished with value: 2281.0 and parameters: {'lr': 0.002087787254175348}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.92459066212177 Correct Prediction: 2063 Accuracy:0.03438333421945572 Time: 45.02786636352539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.13006961345673 Correct Prediction: 2088 Accuracy:0.03480000048875809 Time: 45.548951148986816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.99878884851933 Correct Prediction: 2199 Accuracy:0.036650002002716064 Time: 44.933337450027466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:45:54,377]\u001b[0m Trial 3 finished with value: 2281.0 and parameters: {'lr': 0.0009526589094482116}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 183.39862179756165 Correct Prediction: 2037 Accuracy:0.03395000100135803 Time: 44.838380575180054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 181.1250863224268 Correct Prediction: 1982 Accuracy:0.0330333337187767 Time: 44.9112389087677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.6659322977066 Correct Prediction: 2058 Accuracy:0.034299999475479126 Time: 44.9901397228241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:50:28,940]\u001b[0m Trial 4 finished with value: 2076.0 and parameters: {'lr': 6.769856472600791e-05}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1038 Total Correct Predicted2076 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 183.33768579363823 Correct Prediction: 2036 Accuracy:0.033933334052562714 Time: 45.13202500343323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 181.6692270040512 Correct Prediction: 2036 Accuracy:0.033933334052562714 Time: 45.69131684303284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.96303594112396 Correct Prediction: 2057 Accuracy:0.03428333252668381 Time: 44.83203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:55:05,558]\u001b[0m Trial 5 finished with value: 1775.0 and parameters: {'lr': 4.1700829926669675e-05}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0887 Total Correct Predicted1775 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 971.7464608699083 Correct Prediction: 1999 Accuracy:0.03331666812300682 Time: 45.057127237319946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 204.29187820851803 Correct Prediction: 1903 Accuracy:0.031716667115688324 Time: 45.57479667663574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 631.4630866795778 Correct Prediction: 1903 Accuracy:0.031716667115688324 Time: 45.11993169784546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 00:59:41,862]\u001b[0m Trial 6 finished with value: 2014.0 and parameters: {'lr': 0.056341584630650615}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1007 Total Correct Predicted2014 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 186.3309024721384 Correct Prediction: 2018 Accuracy:0.03363333269953728 Time: 45.19293189048767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 183.192331507802 Correct Prediction: 2055 Accuracy:0.03424999862909317 Time: 45.37890911102295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 182.2498294711113 Correct Prediction: 2008 Accuracy:0.03346666693687439 Time: 45.39784288406372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:04:19,834]\u001b[0m Trial 7 finished with value: 2076.0 and parameters: {'lr': 1.8407061731562152e-05}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1038 Total Correct Predicted2076 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 187.25818964838982 Correct Prediction: 2012 Accuracy:0.033533334732055664 Time: 45.40235137939453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 182.8911650776863 Correct Prediction: 2016 Accuracy:0.03359999880194664 Time: 45.4113335609436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 182.0205807685852 Correct Prediction: 2091 Accuracy:0.03485000133514404 Time: 45.13966608047485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:08:57,419]\u001b[0m Trial 8 finished with value: 2093.0 and parameters: {'lr': 2.2435281430624855e-05}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1047 Total Correct Predicted2093 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 2963.1122988313437 Correct Prediction: 1973 Accuracy:0.032883334904909134 Time: 45.676345109939575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 385.19116066396236 Correct Prediction: 1942 Accuracy:0.032366666942834854 Time: 45.514761209487915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 2015.343149855733 Correct Prediction: 1969 Accuracy:0.03281666710972786 Time: 45.459125995635986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:13:34,780]\u001b[0m Trial 9 finished with value: 2281.0 and parameters: {'lr': 0.08528430102912482}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.88712684810162 Correct Prediction: 1995 Accuracy:0.033250000327825546 Time: 45.19091296195984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 181.79148076474667 Correct Prediction: 1975 Accuracy:0.03291666880249977 Time: 45.03160214424133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 181.8253290206194 Correct Prediction: 2016 Accuracy:0.03359999880194664 Time: 44.85545110702515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:18:09,913]\u001b[0m Trial 10 finished with value: 1775.0 and parameters: {'lr': 0.010573010052262844}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0887 Total Correct Predicted1775 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.11644381284714 Correct Prediction: 2042 Accuracy:0.03403333202004433 Time: 45.028972148895264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.00687040388584 Correct Prediction: 2191 Accuracy:0.036516666412353516 Time: 44.6030216217041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.89260616898537 Correct Prediction: 2215 Accuracy:0.036916665732860565 Time: 45.107321977615356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:22:44,639]\u001b[0m Trial 11 finished with value: 1994.0 and parameters: {'lr': 0.0035474078500299802}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.04692742228508 Correct Prediction: 2080 Accuracy:0.03466666862368584 Time: 45.269646883010864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.08933736383915 Correct Prediction: 2097 Accuracy:0.034949999302625656 Time: 45.2088840007782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.984437584877 Correct Prediction: 2159 Accuracy:0.035983335226774216 Time: 45.25390100479126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:27:22,538]\u001b[0m Trial 12 finished with value: 2281.0 and parameters: {'lr': 0.0010256547685590291}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 184.59656310081482 Correct Prediction: 1992 Accuracy:0.03319999948143959 Time: 45.256866216659546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 185.0033303797245 Correct Prediction: 1952 Accuracy:0.03253333270549774 Time: 45.65752577781677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 186.2573176473379 Correct Prediction: 1946 Accuracy:0.03243333473801613 Time: 45.136723279953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:31:58,990]\u001b[0m Trial 13 finished with value: 1994.0 and parameters: {'lr': 0.016312155673884693}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.3054707199335 Correct Prediction: 2015 Accuracy:0.03358333185315132 Time: 45.138848066329956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.16331079602242 Correct Prediction: 2100 Accuracy:0.03500000014901161 Time: 45.59842085838318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.9984120130539 Correct Prediction: 2187 Accuracy:0.03644999861717224 Time: 45.32948708534241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:36:36,807]\u001b[0m Trial 14 finished with value: 1922.0 and parameters: {'lr': 0.00045703432910437503}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0961 Total Correct Predicted1922 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.04956732690334 Correct Prediction: 1992 Accuracy:0.03319999948143959 Time: 45.09844970703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.2196361720562 Correct Prediction: 2049 Accuracy:0.03415000066161156 Time: 44.921788692474365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.67259900271893 Correct Prediction: 2087 Accuracy:0.03478333353996277 Time: 45.22308015823364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:41:13,523]\u001b[0m Trial 15 finished with value: 1994.0 and parameters: {'lr': 0.006631827283878645}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 196.63262067735195 Correct Prediction: 1970 Accuracy:0.03283333405852318 Time: 44.88378858566284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 188.12613973021507 Correct Prediction: 1974 Accuracy:0.03290000185370445 Time: 45.183603048324585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 194.51198115944862 Correct Prediction: 1901 Accuracy:0.03168333321809769 Time: 45.042524099349976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:45:49,148]\u001b[0m Trial 16 finished with value: 1929.0 and parameters: {'lr': 0.02588009612587456}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0964 Total Correct Predicted1929 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.9982886761427 Correct Prediction: 2035 Accuracy:0.033916667103767395 Time: 45.46368622779846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.3239392787218 Correct Prediction: 2067 Accuracy:0.03445000201463699 Time: 44.993237257003784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.0900021791458 Correct Prediction: 2129 Accuracy:0.035483334213495255 Time: 45.17303943634033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:50:26,063]\u001b[0m Trial 17 finished with value: 1922.0 and parameters: {'lr': 0.0002553079076785416}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0961 Total Correct Predicted1922 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.91778503358364 Correct Prediction: 2051 Accuracy:0.034183334559202194 Time: 45.4127402305603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.12117120623589 Correct Prediction: 2083 Accuracy:0.034716665744781494 Time: 45.26326131820679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.94833540916443 Correct Prediction: 2217 Accuracy:0.0369499996304512 Time: 45.09301829338074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:55:02,458]\u001b[0m Trial 18 finished with value: 1994.0 and parameters: {'lr': 0.0013107352832411052}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.88661669194698 Correct Prediction: 2034 Accuracy:0.033900000154972076 Time: 45.44407391548157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.26504881680012 Correct Prediction: 2109 Accuracy:0.03514999896287918 Time: 45.05051565170288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.07092407345772 Correct Prediction: 2099 Accuracy:0.03498333320021629 Time: 45.6569926738739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 01:59:38,595]\u001b[0m Trial 19 finished with value: 1994.0 and parameters: {'lr': 0.00044845641681714744}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.95465816557407 Correct Prediction: 2081 Accuracy:0.034683335572481155 Time: 45.016711711883545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 179.96545380353928 Correct Prediction: 2192 Accuracy:0.036533333361148834 Time: 45.73105239868164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.99782916903496 Correct Prediction: 2179 Accuracy:0.03631666675209999 Time: 45.153037786483765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:04:16,409]\u001b[0m Trial 20 finished with value: 1994.0 and parameters: {'lr': 0.004299304190980805}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.91302494704723 Correct Prediction: 1991 Accuracy:0.03318333253264427 Time: 45.49993443489075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 179.99742360413074 Correct Prediction: 2181 Accuracy:0.03635000064969063 Time: 45.8406937122345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.88374261558056 Correct Prediction: 2257 Accuracy:0.03761666640639305 Time: 45.920684576034546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:08:54,614]\u001b[0m Trial 21 finished with value: 2281.0 and parameters: {'lr': 0.0022674079110312747}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 1523.4607912749052 Correct Prediction: 1954 Accuracy:0.03256666660308838 Time: 45.44494080543518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 226.09933007508516 Correct Prediction: 1979 Accuracy:0.03298333287239075 Time: 45.63000440597534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 4051.3027824163437 Correct Prediction: 2018 Accuracy:0.03363333269953728 Time: 45.48107075691223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:13:33,545]\u001b[0m Trial 22 finished with value: 1971.0 and parameters: {'lr': 0.0822735322259136}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0985 Total Correct Predicted1971 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 191.44173085689545 Correct Prediction: 1962 Accuracy:0.03270000219345093 Time: 46.09657597541809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 192.32457511126995 Correct Prediction: 1968 Accuracy:0.03280000016093254 Time: 45.651028633117676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 195.78877334296703 Correct Prediction: 1908 Accuracy:0.03180000185966492 Time: 45.24463200569153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:18:12,546]\u001b[0m Trial 23 finished with value: 1971.0 and parameters: {'lr': 0.02613221784481664}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0985 Total Correct Predicted1971 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.01984922587872 Correct Prediction: 1974 Accuracy:0.03290000185370445 Time: 45.589298725128174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.14234705269337 Correct Prediction: 2129 Accuracy:0.035483334213495255 Time: 45.33074879646301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.94771844148636 Correct Prediction: 2181 Accuracy:0.03635000064969063 Time: 45.182950496673584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:22:49,281]\u001b[0m Trial 24 finished with value: 1994.0 and parameters: {'lr': 0.0019229932607486649}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 370.7442502230406 Correct Prediction: 1918 Accuracy:0.031966667622327805 Time: 45.29314732551575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 187.81498077511787 Correct Prediction: 1909 Accuracy:0.031816668808460236 Time: 45.63616323471069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 187.84324905276299 Correct Prediction: 1946 Accuracy:0.03243333473801613 Time: 46.0599308013916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:27:27,687]\u001b[0m Trial 25 finished with value: 1775.0 and parameters: {'lr': 0.04534766293963146}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0887 Total Correct Predicted1775 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 310.6098975390196 Correct Prediction: 1919 Accuracy:0.03198333457112312 Time: 46.17144441604614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 6562.8069043159485 Correct Prediction: 1926 Accuracy:0.032099999487400055 Time: 45.19201469421387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 236.8663633465767 Correct Prediction: 1945 Accuracy:0.03241666778922081 Time: 45.371323585510254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:32:07,448]\u001b[0m Trial 26 finished with value: 1775.0 and parameters: {'lr': 0.0987529126737173}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0887 Total Correct Predicted1775 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.34467129409313 Correct Prediction: 1991 Accuracy:0.03318333253264427 Time: 45.81082487106323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.16366581618786 Correct Prediction: 2114 Accuracy:0.035233333706855774 Time: 45.413426637649536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.0558859705925 Correct Prediction: 2100 Accuracy:0.03500000014901161 Time: 45.977673292160034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:36:46,340]\u001b[0m Trial 27 finished with value: 2281.0 and parameters: {'lr': 0.0005210569770971885}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 183.03258745372295 Correct Prediction: 2031 Accuracy:0.03384999930858612 Time: 45.6951105594635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.7825599461794 Correct Prediction: 2066 Accuracy:0.034433335065841675 Time: 45.65615177154541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.3785924166441 Correct Prediction: 2162 Accuracy:0.03603333234786987 Time: 45.76927042007446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:41:23,638]\u001b[0m Trial 28 finished with value: 1945.0 and parameters: {'lr': 0.00014587917671152678}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0973 Total Correct Predicted1945 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.5535520762205 Correct Prediction: 1945 Accuracy:0.03241666778922081 Time: 45.986127614974976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.7083501815796 Correct Prediction: 2023 Accuracy:0.03371666744351387 Time: 45.54913902282715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 181.48681192100048 Correct Prediction: 2001 Accuracy:0.03335000202059746 Time: 45.06425070762634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:46:01,131]\u001b[0m Trial 29 finished with value: 1994.0 and parameters: {'lr': 0.009089508996380743}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.60931223630905 Correct Prediction: 2050 Accuracy:0.034166667610406876 Time: 45.28298211097717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.33952440321445 Correct Prediction: 2074 Accuracy:0.034566666930913925 Time: 45.13807153701782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.12932486832142 Correct Prediction: 2178 Accuracy:0.03629999980330467 Time: 45.626479625701904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:50:38,415]\u001b[0m Trial 30 finished with value: 2076.0 and parameters: {'lr': 0.0001876239676525355}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1038 Total Correct Predicted2076 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.32470485568047 Correct Prediction: 2076 Accuracy:0.03460000082850456 Time: 45.613041639328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.21305678784847 Correct Prediction: 2080 Accuracy:0.03466666862368584 Time: 45.250043630599976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.05037301778793 Correct Prediction: 2149 Accuracy:0.03581666573882103 Time: 45.063546657562256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:55:15,019]\u001b[0m Trial 31 finished with value: 1994.0 and parameters: {'lr': 0.00047846687066419497}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.0913178473711 Correct Prediction: 1995 Accuracy:0.033250000327825546 Time: 44.94253206253052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.03964386880398 Correct Prediction: 2153 Accuracy:0.035883333534002304 Time: 45.02212429046631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.8737534582615 Correct Prediction: 2227 Accuracy:0.03711666539311409 Time: 44.816280126571655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 02:59:53,117]\u001b[0m Trial 32 finished with value: 2281.0 and parameters: {'lr': 0.002311839972175859}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.03438633680344 Correct Prediction: 2036 Accuracy:0.033933334052562714 Time: 45.40634369850159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.13907700777054 Correct Prediction: 2087 Accuracy:0.03478333353996277 Time: 45.632282733917236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.03424789011478 Correct Prediction: 2185 Accuracy:0.0364166684448719 Time: 45.416736364364624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:04:30,065]\u001b[0m Trial 33 finished with value: 1994.0 and parameters: {'lr': 0.0007623391934508023}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.96028432250023 Correct Prediction: 2024 Accuracy:0.03373333439230919 Time: 45.49440026283264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 179.99487380683422 Correct Prediction: 2174 Accuracy:0.0362333320081234 Time: 45.58225774765015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.86129926145077 Correct Prediction: 2259 Accuracy:0.03765000030398369 Time: 45.023725509643555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:09:07,564]\u001b[0m Trial 34 finished with value: 2281.0 and parameters: {'lr': 0.002814979365983302}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.5750086903572 Correct Prediction: 1993 Accuracy:0.03321666643023491 Time: 45.325454235076904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.6861962378025 Correct Prediction: 2059 Accuracy:0.034316666424274445 Time: 44.98993968963623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.36659464240074 Correct Prediction: 2076 Accuracy:0.03460000082850456 Time: 45.71692180633545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:13:46,036]\u001b[0m Trial 35 finished with value: 2014.0 and parameters: {'lr': 8.114574881593744e-05}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1007 Total Correct Predicted2014 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.1565294265747 Correct Prediction: 1979 Accuracy:0.03298333287239075 Time: 45.341853618621826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.04117396473885 Correct Prediction: 2151 Accuracy:0.03584999963641167 Time: 45.36970663070679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.23587653040886 Correct Prediction: 2145 Accuracy:0.035750001668930054 Time: 44.910841941833496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:18:23,628]\u001b[0m Trial 36 finished with value: 1994.0 and parameters: {'lr': 0.0055649596142912676}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.1700804978609 Correct Prediction: 2003 Accuracy:0.0333833321928978 Time: 45.5604932308197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.22928845882416 Correct Prediction: 2104 Accuracy:0.035066667944192886 Time: 44.99932837486267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.022225856781 Correct Prediction: 2158 Accuracy:0.0359666682779789 Time: 44.67330837249756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:22:59,444]\u001b[0m Trial 37 finished with value: 1994.0 and parameters: {'lr': 0.0012064345185463922}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.57698233425617 Correct Prediction: 2075 Accuracy:0.034583333879709244 Time: 45.28299283981323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.11254267394543 Correct Prediction: 2167 Accuracy:0.036116667091846466 Time: 45.406065940856934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.0216919928789 Correct Prediction: 2098 Accuracy:0.034966666251420975 Time: 44.7437059879303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:27:35,257]\u001b[0m Trial 38 finished with value: 2281.0 and parameters: {'lr': 0.0006659367737514863}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.97980600595474 Correct Prediction: 2002 Accuracy:0.03336666524410248 Time: 45.624077558517456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.07348504662514 Correct Prediction: 2135 Accuracy:0.03558333218097687 Time: 45.47550368309021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.87868358194828 Correct Prediction: 2222 Accuracy:0.037033334374427795 Time: 45.08089470863342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:32:14,170]\u001b[0m Trial 39 finished with value: 1994.0 and parameters: {'lr': 0.002146755084681912}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.0997 Total Correct Predicted1994 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 182.23597069084644 Correct Prediction: 2085 Accuracy:0.03474999964237213 Time: 44.92297387123108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.28110882639885 Correct Prediction: 2101 Accuracy:0.03501666709780693 Time: 45.337159395217896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.13710741698742 Correct Prediction: 2118 Accuracy:0.03530000150203705 Time: 45.48346829414368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:36:50,287]\u001b[0m Trial 40 finished with value: 2281.0 and parameters: {'lr': 0.0002786774836404291}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 181.0086444169283 Correct Prediction: 2081 Accuracy:0.034683335572481155 Time: 44.797179222106934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 180.14217288792133 Correct Prediction: 2132 Accuracy:0.03553333505988121 Time: 45.24765157699585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 180.04635372757912 Correct Prediction: 2049 Accuracy:0.03415000066161156 Time: 45.35052943229675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:41:27,739]\u001b[0m Trial 41 finished with value: 2281.0 and parameters: {'lr': 0.0008136032494908187}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [1/3], Loss: 180.91938523948193 Correct Prediction: 2018 Accuracy:0.03363333269953728 Time: 44.97957921028137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [2/3], Loss: 179.9766634553671 Correct Prediction: 2166 Accuracy:0.03610000014305115 Time: 45.003390073776245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train]Epoch [3/3], Loss: 179.86961555480957 Correct Prediction: 2235 Accuracy:0.03725000098347664 Time: 45.787787675857544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n",
            "\u001b[32m[I 2022-01-15 03:46:03,249]\u001b[0m Trial 42 finished with value: 2281.0 and parameters: {'lr': 0.0030187073370845367}. Best is trial 0 with value: 2281.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------------Accuracy: 0.1140 Total Correct Predicted2281 out of 20000------------|\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning:\n",
            "\n",
            "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cceb8b32a7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 3. Create a study object and optimize the objective function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-cceb8b32a7b4>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'lr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mOptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_gnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalidationGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-42396f86ddd9>\u001b[0m in \u001b[0;36mtrain_gnn\u001b[0;34m(model, batch_size, num_epochs, Criterion, Optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcount_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;34m'''Receive an array of fds over an AF_UNIX socket.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 1. Define an objective function to be maximized.\n",
        "def objective(trial):\n",
        "\n",
        "\n",
        "    model = GAT().cuda()\n",
        "    params = model.parameters()\n",
        "    Criterion = F.nll_loss\n",
        "    lr = trial.suggest_float(f'lr',1e-5,1e-1,log=True)\n",
        "    Optimizer = torch.optim.Adam(params, lr=lr, weight_decay=5e-4)\n",
        "    train_gnn(model,16, 3, Criterion,Optimizer)\n",
        "    return validationGNN(model,1)\n",
        "\n",
        "# 3. Create a study object and optimize the objective function.\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrRhIgjRimXF"
      },
      "outputs": [],
      "source": [
        "[-2.3249, -2.2992, -2.2826, -2.2780, -2.3314, -2.2974, -2.2823, -2.3386,\n",
        "        -2.3001, -2.2935]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSGCxfWJuEpK"
      },
      "outputs": [],
      "source": [
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "print(f\"input {input}\")\n",
        "print(f\"Softmax input {F.log_softmax(input)}\")\n",
        "target = torch.tensor([1, 0, 4])\n",
        "print(f\"target {target}\")\n",
        "output = F.nll_loss(F.log_softmax(input), target)\n",
        "print(output)\n",
        "output.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjF7J0oO-nFp"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        print(edge_index .dtype)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "data = dataset[0].to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhGyn9vElnOf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_scatter import scatter_mean\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.transforms import BaseTransform\n",
        "\n",
        "\n",
        "class ToSLIC(BaseTransform):\n",
        "    \"\"\"Converts an image to a superpixel representation using the\n",
        "    :meth:`skimage.segmentation.slic` algorithm, resulting in a\n",
        "    :obj:`torch_geometric.data.Data` object holding the centroids of\n",
        "    superpixels in :obj:`pos` and their mean color in :obj:`x`.\n",
        "\n",
        "    This transform can be used with any :obj:`torchvision` dataset.\n",
        "\n",
        "    Example::\n",
        "\n",
        "        from torchvision.datasets import MNIST\n",
        "        import torchvision.transforms as T\n",
        "        from torch_geometric.transforms import ToSLIC\n",
        "\n",
        "        transform = T.Compose([T.ToTensor(), ToSLIC(n_segments=75)])\n",
        "        dataset = MNIST('/tmp/MNIST', download=True, transform=transform)\n",
        "\n",
        "    Args:\n",
        "        add_seg (bool, optional): If set to `True`, will add the segmentation\n",
        "            result to the data object. (default: :obj:`False`)\n",
        "        add_img (bool, optional): If set to `True`, will add the input image\n",
        "            to the data object. (default: :obj:`False`)\n",
        "        **kwargs (optional): Arguments to adjust the output of the SLIC\n",
        "            algorithm. See the `SLIC documentation\n",
        "            <https://scikit-image.org/docs/dev/api/skimage.segmentation.html\n",
        "            #skimage.segmentation.slic>`_ for an overview.\n",
        "    \"\"\"\n",
        "    def __init__(self, add_seg=False, add_img=False, **kwargs):\n",
        "        self.add_seg = add_seg\n",
        "        self.add_img = add_img\n",
        "        self.kwargs = kwargs\n",
        "\n",
        "    def __call__(self, img):\n",
        "        from skimage.segmentation import slic\n",
        "\n",
        "        img = img.permute(1, 2, 0)\n",
        "        h, w, c = img.size()\n",
        "\n",
        "        seg = slic(img.to(torch.double).numpy(), start_label=0, **self.kwargs)\n",
        "        seg = torch.from_numpy(seg)\n",
        "\n",
        "        x = scatter_mean(img.view(h * w, c), seg.view(h * w), dim=0)\n",
        "\n",
        "        pos_y = torch.arange(h, dtype=torch.float)\n",
        "        pos_y = pos_y.view(-1, 1).repeat(1, w).view(h * w)\n",
        "        pos_x = torch.arange(w, dtype=torch.float)\n",
        "        pos_x = pos_x.view(1, -1).repeat(h, 1).view(h * w)\n",
        "\n",
        "        pos = torch.stack([pos_x, pos_y], dim=-1)\n",
        "        pos = scatter_mean(pos, seg.view(h * w), dim=0)\n",
        "\n",
        "        data = Data(x=x, pos=pos)\n",
        "\n",
        "        if self.add_seg:\n",
        "            data.seg = seg.view(1, h, w)\n",
        "\n",
        "        if self.add_img:\n",
        "            data.img = img.permute(2, 0, 1).view(1, c, h, w)\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as T\n",
        "from torch_geometric.transforms import ToSLIC\n",
        "\n",
        "transform = T.Compose([T.ToTensor(), ToSLIC(n_segments=75)])\n",
        "dataset = MNIST('/tmp/MNIST', download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-98GJOEOWYUK"
      },
      "outputs": [],
      "source": [
        "class GraphVisualization:\n",
        "   \n",
        "    def __init__(self,graph):\n",
        "          \n",
        "        # visual is a list which stores all \n",
        "        # the set of edges that constitutes a\n",
        "        # graph\n",
        "        self.visual = graph['pos'].numpy().reshape(-1,2)\n",
        "        self.labels = graph['x']\n",
        "        \n",
        "        self.label_dict = {}\n",
        "        for idx,label in enumerate(self.labels):\n",
        "          self.label_dict[idx] = str(idx)#+\" : \" + str(label.numpy()[0])\n",
        "        print(self.label_dict)\n",
        "    # In visualize function G is an object of\n",
        "    # class Graph given by networkx G.add_edges_from(visual)\n",
        "    # creates a graph with a given list\n",
        "    # nx.draw_networkx(G) - plots the graph\n",
        "    # plt.show() - displays the graph\n",
        "    def visualize(self):\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(self.visual)\n",
        "        nx.draw_networkx(G, node_size=500)\n",
        "        plt.show()\n",
        "\n",
        "data = dataset[4][0]\n",
        "\n",
        "G = GraphVisualization(data)\n",
        "G.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clFdlkNxmUgj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Oqnlk0k1-6"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr4xZHSyn3tx"
      },
      "source": [
        "## Detach and Crop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "splkmehhzqKM"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoIROxQQn6Hh"
      },
      "outputs": [],
      "source": [
        "# training and validation loss were calculated after every epoch\n",
        "def transform(img):\n",
        "    transform = transforms.Compose([\n",
        "    transforms.RandomApply(transforms = [\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "      # transforms.RandomApply(\n",
        "      #     [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],\n",
        "      #     p=0.8\n",
        "      # ),\n",
        "      transforms.RandomRotation(\n",
        "          degrees=45\n",
        "      ),  # Perhaps a random rotation from -45 to 45 degrees\n",
        "    #   #transforms.RandomInvert(),\n",
        "    #   #transforms.RandomEqualize(),\n",
        "    #   # transforms.RandomHorizontalFlip(\n",
        "    #   #     p=0.5\n",
        "    #   # ),  # Flips the image horizontally with probability 0.5\n",
        "    #   # transforms.RandomVerticalFlip(\n",
        "    #   #     p=0.05\n",
        "    #   # ),  # Flips image vertically with probability 0.05\n",
        "\n",
        "    transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))\n",
        "    ], p =0.3),\n",
        "    transforms.ToTensor()  # Finally converts PIL image to tensor so we can train w. pytorch\n",
        "    # transforms.Normalize(\n",
        "    #     mean=[0.5], std=[0.5]\n",
        "    # ), \n",
        "    ])\n",
        "    transformed_img = transform(img).numpy()\n",
        "    return transformed_img\n",
        "\n",
        "def detach_cropped_area(im,coods,debug = False):\n",
        "  im_width = 224\n",
        "  im_height = 224\n",
        "  area = coods\n",
        "  cropped_img = im.crop(area)\n",
        "  newimage = cropped_img.resize((im_width,im_height))\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  scaler.fit(newimage)\n",
        "  newimage = scaler.transform(newimage)\n",
        "  #numpy_array = np.asarray(cropped_img)\n",
        "  # if debug == True && False:\n",
        "  #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  # print(newimage)\n",
        "  # pyplot.imshow(newimage)\n",
        "  # pyplot.show()\n",
        "  #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "  # if debug == True:\n",
        "  #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "  #   pyplot.show()\n",
        "  return transform(Image.fromarray(newimage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9eDs6Izr80"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlljH5_uztNF"
      },
      "outputs": [],
      "source": [
        "def detach_cropped_area_test(im,coods,debug = False):\n",
        "  im_width = 224\n",
        "  im_height = 224\n",
        "  area = coods\n",
        "  cropped_img = im.crop(area)\n",
        "  newimage = cropped_img.resize((im_width,im_height))\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  scaler.fit(newimage)\n",
        "  newimage = scaler.transform(newimage)\n",
        "  #numpy_array = np.asarray(cropped_img)\n",
        "  # if debug == True && False:\n",
        "  #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  # print(newimage)\n",
        "  # pyplot.imshow(newimage)\n",
        "  # pyplot.show()\n",
        "  #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "  # if debug == True:\n",
        "  #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "  #   pyplot.show()\n",
        "  return newimage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_9ggEd06_o"
      },
      "source": [
        "## Test Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKzqdV0ayuqE"
      },
      "outputs": [],
      "source": [
        "class DatasetTest(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "        self.label =[]\n",
        "        self.images = []\n",
        "        self.img_width,self.img_height = width,height\n",
        "        start_time = time.time()\n",
        "        for i in range(num_samples):\n",
        "          self.image,input_digits,selected_digit = environment.reset()\n",
        "          self.images.append(self.image)\n",
        "          self.label.append(input_digits.index(selected_digit))\n",
        "        print(\"|------Test Dataset Generated------|\")\n",
        "        print(f\"Total Images {np.array(self.images).shape} Labels {len(self.label)} Time to load: {time.time() - start_time} seconds\")\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        im = Image.fromarray(self.images[idx])\n",
        "        label = self.label[idx]\n",
        "        input_1 = torch.tensor(detach_cropped_area_test(im,(0, 10, 52, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        label_1 = torch.tensor(detach_cropped_area_test(im,(0, 52, 52, 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        input_2 = torch.tensor(detach_cropped_area_test(im,(85, 10, 130, 52)), dtype=torch.float32).reshape(1,self.img_width,self.img_height )\n",
        "        label_2 = torch.tensor(detach_cropped_area_test(im,(85, 52, 130 , 82)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "        query = torch.tensor(detach_cropped_area_test(im,(180, 35, 230 , 60)), dtype=torch.float32).reshape(1,self.img_width,self.img_height)\n",
        "\n",
        "\n",
        "        return  input_1, label_1, input_2 , label_2, query, label\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return len(self.images)\n",
        "testDataset = DatasetTest(300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9o9OyR-k3hK"
      },
      "source": [
        "## Trunc Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZUB1Ar1k7sa"
      },
      "outputs": [],
      "source": [
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
        "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaY52yzyNt5T"
      },
      "source": [
        "## Lars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "susYKNfMNvNr"
      },
      "outputs": [],
      "source": [
        "class LARS(torch.optim.Optimizer):\n",
        "    \"\"\"\n",
        "    Almost copy-paste from https://github.com/facebookresearch/barlowtwins/blob/main/main.py\n",
        "    \"\"\"\n",
        "    def __init__(self, params, lr=0, weight_decay=0, momentum=0.9, eta=0.001,\n",
        "                 weight_decay_filter=None, lars_adaptation_filter=None):\n",
        "        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum,\n",
        "                        eta=eta, weight_decay_filter=weight_decay_filter,\n",
        "                        lars_adaptation_filter=lars_adaptation_filter)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self):\n",
        "        for g in self.param_groups:\n",
        "            for p in g['params']:\n",
        "                dp = p.grad\n",
        "\n",
        "                if dp is None:\n",
        "                    continue\n",
        "\n",
        "                if p.ndim != 1:\n",
        "                    dp = dp.add(p, alpha=g['weight_decay'])\n",
        "\n",
        "                if p.ndim != 1:\n",
        "                    param_norm = torch.norm(p)\n",
        "                    update_norm = torch.norm(dp)\n",
        "                    one = torch.ones_like(param_norm)\n",
        "                    q = torch.where(param_norm > 0.,\n",
        "                                    torch.where(update_norm > 0,\n",
        "                                                (g['eta'] * param_norm / update_norm), one), one)\n",
        "                    dp = dp.mul(q)\n",
        "\n",
        "                param_state = self.state[p]\n",
        "                if 'mu' not in param_state:\n",
        "                    param_state['mu'] = torch.zeros_like(p)\n",
        "                mu = param_state['mu']\n",
        "                mu.mul_(g['momentum']).add_(dp)\n",
        "\n",
        "                p.add_(mu, alpha=-g['lr'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5K0FivvORuK"
      },
      "source": [
        "## Get Param Groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm20E4wKOT7i"
      },
      "outputs": [],
      "source": [
        "def get_params_groups(model):\n",
        "    regularized = []\n",
        "    not_regularized = []\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        # we do not regularize biases nor Norm parameters\n",
        "        if name.endswith(\".bias\") or len(param.shape) == 1:\n",
        "            not_regularized.append(param)\n",
        "        else:\n",
        "            regularized.append(param)\n",
        "    return [{'params': regularized}, {'params': not_regularized, 'weight_decay': 0.}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU-M7iskARD"
      },
      "source": [
        "# Vision Transformer (ViT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmiPgnGkjyK"
      },
      "source": [
        "### Patch Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o7SpFudkmLC"
      },
      "outputs": [],
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\" Image to Patch Embedding\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=1, embed_dim=768):\n",
        "        super().__init__()\n",
        "        num_patches = (img_size // patch_size) * (img_size // patch_size)\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cns8Hit_kJ4q"
      },
      "source": [
        "### DropPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUvCOJslkMwC"
      },
      "outputs": [],
      "source": [
        "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
        "    if drop_prob == 0. or not training:\n",
        "        return x\n",
        "    keep_prob = 1 - drop_prob\n",
        "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
        "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "    random_tensor.floor_()  # binarize\n",
        "    output = x.div(keep_prob) * random_tensor\n",
        "    return output\n",
        "\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
        "    \"\"\"\n",
        "    def __init__(self, drop_prob=None):\n",
        "        super(DropPath, self).__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "    def forward(self, x):\n",
        "        return drop_path(x, self.drop_prob, self.training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6AjTmFxkPMq"
      },
      "source": [
        "### Multi Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXKCNHT_kOza"
      },
      "outputs": [],
      "source": [
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoNI9GLGkZTK"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SIhH1lhkakq"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=16, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = qk_scale or head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzy9mX3kkc1C"
      },
      "source": [
        "### Attention Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ErM1Xxkfpa"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
        "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = Attention(\n",
        "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
        "\n",
        "    def forward(self, x, return_attention=False):\n",
        "        y, attn = self.attn(self.norm1(x))\n",
        "        if return_attention:\n",
        "            return attn\n",
        "        x = x + self.drop_path(y)\n",
        "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5rBokmyksRq"
      },
      "source": [
        "### Vision Transformer Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7K__p_BkqsK"
      },
      "outputs": [],
      "source": [
        "class VisionTransformer(nn.Module):\n",
        "    \"\"\" Vision Transformer \"\"\"\n",
        "    def __init__(self, img_size=[224], patch_size=8, in_chans=1, num_classes=0, embed_dim=768, depth=12,\n",
        "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
        "                 drop_path_rate=0., norm_layer=nn.LayerNorm, **kwargs):\n",
        "        super().__init__()\n",
        "        self.num_features = self.embed_dim = embed_dim\n",
        "\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            img_size=img_size[0], patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
        "\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Block(\n",
        "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
        "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
        "            for i in range(depth)])\n",
        "        self.norm = norm_layer(embed_dim)\n",
        "\n",
        "        # Classifier head\n",
        "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
        "\n",
        "        trunc_normal_(self.pos_embed, std=.02)\n",
        "        trunc_normal_(self.cls_token, std=.02)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            trunc_normal_(m.weight, std=.02)\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(m.weight, 1.0)\n",
        "\n",
        "    def interpolate_pos_encoding(self, x, w, h):\n",
        "        npatch = x.shape[1] - 1\n",
        "        N = self.pos_embed.shape[1] - 1\n",
        "        if npatch == N and w == h:\n",
        "            return self.pos_embed\n",
        "        class_pos_embed = self.pos_embed[:, 0]\n",
        "        patch_pos_embed = self.pos_embed[:, 1:]\n",
        "        dim = x.shape[-1]\n",
        "        w0 = w // self.patch_embed.patch_size\n",
        "        h0 = h // self.patch_embed.patch_size\n",
        "        # we add a small number to avoid floating point error in the interpolation\n",
        "        # see discussion at https://github.com/facebookresearch/dino/issues/8\n",
        "        w0, h0 = w0 + 0.1, h0 + 0.1\n",
        "        patch_pos_embed = nn.functional.interpolate(\n",
        "            patch_pos_embed.reshape(1, int(math.sqrt(N)), int(math.sqrt(N)), dim).permute(0, 3, 1, 2),\n",
        "            scale_factor=(w0 / math.sqrt(N), h0 / math.sqrt(N)),\n",
        "            mode='bicubic',\n",
        "        )\n",
        "        assert int(w0) == patch_pos_embed.shape[-2] and int(h0) == patch_pos_embed.shape[-1]\n",
        "        patch_pos_embed = patch_pos_embed.permute(0, 2, 3, 1).view(1, -1, dim)\n",
        "        return torch.cat((class_pos_embed.unsqueeze(0), patch_pos_embed), dim=1)\n",
        "\n",
        "    def prepare_tokens(self, x):\n",
        "        B, nc, w, h = x.shape\n",
        "        x = self.patch_embed(x)  # patch linear embedding\n",
        "\n",
        "        # add the [CLS] token to the embed patch tokens\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        # add positional encoding to each token\n",
        "        x = x + self.interpolate_pos_encoding(x, w, h)\n",
        "\n",
        "        return self.pos_drop(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.prepare_tokens(x)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        return x[:, 0]\n",
        "\n",
        "    def get_last_selfattention(self, x):\n",
        "        x = self.prepare_tokens(x)\n",
        "        for i, blk in enumerate(self.blocks):\n",
        "            if i < len(self.blocks) - 1:\n",
        "                x = blk(x)\n",
        "            else:\n",
        "                # return attention of the last block\n",
        "                return blk(x, return_attention=True)\n",
        "\n",
        "    def get_intermediate_layers(self, x, n=1):\n",
        "        x = self.prepare_tokens(x)\n",
        "        # we return the output tokens from the `n` last blocks\n",
        "        output = []\n",
        "        for i, blk in enumerate(self.blocks):\n",
        "            x = blk(x)\n",
        "            if len(self.blocks) - i <= n:\n",
        "                output.append(self.norm(x))\n",
        "        return output\n",
        "\n",
        "\n",
        "def vit_tiny(patch_size=16,embed_dim=192, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=patch_size, embed_dim=embed_dim, depth=12, num_heads=3, mlp_ratio=4,\n",
        "        qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def vit_small(patch_size=16,embed_dim=384, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=patch_size, embed_dim=embed_dim, depth=12, num_heads=6, mlp_ratio=4,\n",
        "        qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def vit_base(patch_size=16,embed_dim=768, **kwargs):\n",
        "    model = VisionTransformer(\n",
        "        patch_size=patch_size, embed_dim=embed_dim, depth=12, num_heads=12, mlp_ratio=4,\n",
        "        qkv_bias=True, norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKJeki4Uiz5y"
      },
      "source": [
        "# Siamsese *Network*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrUbxqMicH79"
      },
      "source": [
        "## Dataloader Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYk-TP2AcHl1"
      },
      "outputs": [],
      "source": [
        "class SiamDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "        self.verbose = verbose\n",
        "        self.img_width,self.img_height = width,height\n",
        "        start_time = time.time()\n",
        "        imgs = []\n",
        "        self.label = []\n",
        "        path = \"/content/drive/MyDrive/Final Project/dataset/train/\"\n",
        "        valid_images = [\".jpg\"]\n",
        "        count =0 \n",
        "        for f in os.listdir(path):\n",
        "            ext = os.path.splitext(f)[1]\n",
        "            if ext.lower() not in valid_images:\n",
        "                continue\n",
        "            if self.verbose:\n",
        "              print(f\"Loaded {count}\")\n",
        "            imgs.append(np.array(Image.open(os.path.join(path,f))))\n",
        "            self.label.append(f[-5])\n",
        "            count = count + 1\n",
        "            if count >= num_samples:\n",
        "              break\n",
        "        self.images = np.array(imgs)\n",
        "        # self.label =[]\n",
        "        # self.images = []\n",
        "        # self.img_width,self.img_height = width,height\n",
        "        # start_time = time.time()\n",
        "        # for i in range(num_samples):\n",
        "        #   self.image,input_digits,selected_digit = environment.reset()\n",
        "        #   self.images.append(self.image)\n",
        "        #   self.label.append(input_digits.index(selected_digit))\n",
        "        print(\"|------Test Dataset Generated------|\")\n",
        "        print(f\"Total Images {np.array(self.images).shape} Labels {len(self.label)} Time to load: {time.time() - start_time} seconds\")\n",
        "        # print(\"|------Dataset Loaded------|\")\n",
        "        # print(f\"Total Images {self.images.shape} Labels {len(self.label)} Time to load: {time.time() - start_time} seconds\")\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        im = Image.fromarray(self.images[idx])\n",
        "        input_1 = detach_cropped_area(im,(0, 10, 52, 52))\n",
        "        label_1 = detach_cropped_area(im,(0, 52, 52, 82))\n",
        "        input_2 = detach_cropped_area(im,(85, 10, 130, 52))\n",
        "        label_2 = detach_cropped_area(im,(85, 52, 130 , 82))\n",
        "        query = detach_cropped_area(im,(180, 35, 230 , 60))\n",
        "        clas = np.random.randint(0,1)\n",
        "        if  clas == 0:#int(self.label[idx])\n",
        "          img1 = torch.tensor(np.reshape(label_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img2 = torch.tensor(np.reshape(input_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          y1 = torch.tensor(np.ones(1,dtype=np.float32),dtype=torch.float32)\n",
        "          img3 = torch.tensor(np.reshape(label_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img4 = torch.tensor(np.reshape(input_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          y2 = torch.tensor(np.zeros(1,dtype=np.float32),dtype=torch.float32)\n",
        "        if clas == 1:\n",
        "          img1 = torch.tensor(np.reshape(label_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img2 = torch.tensor(np.reshape(input_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          y1 = torch.tensor(np.ones(1,dtype=np.float32),dtype=torch.float32)\n",
        "          img3 = torch.tensor(np.reshape(label_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img4 = torch.tensor(np.reshape(input_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          y2 = torch.tensor(np.zeros(1,dtype=np.float32),dtype=torch.float32)\n",
        "\n",
        "        return  img1, img2, y1, img3, img4, y2\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return len(self.images)\n",
        "\n",
        "siamdset = SiamDataset(3000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxK46EbeemAF"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(siamdset, shuffle=True, batch_size=1,num_workers=4)\n",
        "for itr,data in enumerate(train_dataloader):\n",
        "  img1, img2 , label1, img3, img4, label2 = data\n",
        "\n",
        "  # dista =nn.functional.pairwise_distance(output1,output2 )\n",
        "  # distb =nn.functional.pairwise_distance(output3,output4 )\n",
        "  print(\"-------------------------------\")\n",
        "  print(\"-------------------------------\")\n",
        "  print(f\"Label 1 {label1}\")\n",
        "  print(\"------------img1-------------\")\n",
        "  im = pyplot.imshow(img1[0].numpy().reshape(224,224))\n",
        "  pyplot.show()\n",
        "  print(\"------------img2-------------\")\n",
        "  im = pyplot.imshow(img2[0].numpy().reshape(224,224))\n",
        "  pyplot.show()\n",
        "  print(f\"Label 2 {label2}\")\n",
        "  print(\"------------img3-------------\")\n",
        "  im = pyplot.imshow(img3[0].numpy().reshape(224,224))\n",
        "  pyplot.show()\n",
        "  print(\"------------img4-------------\")\n",
        "  im = pyplot.imshow(img4[0].numpy().reshape(224,224))\n",
        "  pyplot.show()\n",
        "  print(\"-------------------------------\")\n",
        "  print(\"-------------------------------\")\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qTq_-j6bXHl"
      },
      "source": [
        "## Validation Accuracy Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71VXpatxbZrA"
      },
      "outputs": [],
      "source": [
        "def validationAccuracy(trained_model):\n",
        "  test_dataloader_mnist = DataLoader(MnistDatasetTest, shuffle=True, batch_size= 1,num_workers=4)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    t_label = []\n",
        "    p_labels = []\n",
        "    for itr,data in enumerate(test_dataloader_mnist):\n",
        "        if itr > 5:\n",
        "          break\n",
        "        img1, img2 , label1, img3, img4, label2 = data\n",
        "        dista= model(img1[0].reshape(1,1,28,28).cuda(),img2[0].reshape(1,1,28,28).cuda())\n",
        "        distb = model(img3[0].reshape(1,1,28,28).cuda(),img4[0].reshape(1,1,28,28).cuda())\n",
        "        # dista =nn.functional.pairwise_distance(output1,output2 )\n",
        "        # distb =nn.functional.pairwise_distance(output3,output4 )\n",
        "        print(\"-------------------------------\")\n",
        "        print(\"-------------------------------\")\n",
        "        print(\"------------img1-------------\")\n",
        "        print(img1.shape)\n",
        "        im = pyplot.imshow(img1[0].numpy().reshape(28,28))\n",
        "        pyplot.show()\n",
        "        print(\"------------img2-------------\")\n",
        "        im = pyplot.imshow(img2[0].numpy().reshape(28,28))\n",
        "        pyplot.show()\n",
        "        print(f\"Similarity Img 1  & Img 2 {dista}\")\n",
        "        print(\"------------img3-------------\")\n",
        "        im = pyplot.imshow(img3[0].numpy().reshape(28,28))\n",
        "        pyplot.show()\n",
        "        print(\"------------img4-------------\")\n",
        "        im = pyplot.imshow(img4[0].numpy().reshape(28,28))\n",
        "        pyplot.show()\n",
        "        print(f\"Similarity Img 3  & Img 4 {distb}\")\n",
        "        print(\"-------------------------------\")\n",
        "        print(\"-------------------------------\")\n",
        "        \n",
        "        \n",
        "        # print(\"------------\")\n",
        "        # print(nn.functional.pairwise_distance(output1,output2 ))\n",
        "        p_label = 0\n",
        "        if (dista[0] > distb[0]):\n",
        "          p_label = 1\n",
        "        t_label.append(1)\n",
        "        p_labels.append(p_label)\n",
        "\n",
        "        print(f\"dista: {dista} distb: {distb}\")   \n",
        "  print(f\"Validation accuracy: {classification_report(t_label,p_labels, target_names=['class 1'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lebHfq-X7Fk"
      },
      "source": [
        "## Validation accuracy custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AouBP5EX4f2"
      },
      "outputs": [],
      "source": [
        "def validationAccuracy_custom(trained_model):\n",
        "  \n",
        "  test_dataloader = DataLoader(testDataset, shuffle=True, batch_size=1,num_workers=4)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    t_label = []\n",
        "    p_labels = []\n",
        "    for itr,data in enumerate(test_dataloader):\n",
        "        # if itr > 5:\n",
        "        #   break\n",
        "        input_1, label_1, input_2 , label_2, query, label = data\n",
        "        img1 =  query\n",
        "        img3 = img1\n",
        "        img2 = input_1\n",
        "        img4 = input_2\n",
        "        dista= model(img1[0].reshape(1,1,224,224).cuda(),img2[0].reshape(1,1,224,224).cuda())\n",
        "        distb = model(img3[0].reshape(1,1,224,224).cuda(),img4[0].reshape(1,1,224,224).cuda())\n",
        "        # dista =nn.functional.pairwise_distance(output1,output2 )\n",
        "        # distb =nn.functional.pairwise_distance(output3,output4 )\n",
        "        # print(\"-------------------------------\")\n",
        "        # print(\"-------------------------------\")\n",
        "        # print(\"------------img1-------------\")\n",
        "        # print(img1.shape)\n",
        "        # im = pyplot.imshow(img1[0].numpy().reshape(224,224))\n",
        "        # pyplot.show()\n",
        "        # print(\"------------img2-------------\")\n",
        "        # im = pyplot.imshow(img2[0].numpy().reshape(224,224))\n",
        "        # pyplot.show()\n",
        "        # print(f\"Similarity Img 1  & Img 2 {dista}\")\n",
        "        # print(\"------------img3-------------\")\n",
        "        # im = pyplot.imshow(img3[0].numpy().reshape(224,224))\n",
        "        # pyplot.show()\n",
        "        # print(\"------------img4-------------\")\n",
        "        # im = pyplot.imshow(img4[0].numpy().reshape(224,224))\n",
        "        # pyplot.show()\n",
        "        # print(f\"Similarity Img 3  & Img 4 {distb}\")\n",
        "        # print(\"-------------------------------\")\n",
        "        # print(\"-------------------------------\")\n",
        "\n",
        "        p_label = 0\n",
        "        if (dista[0] < distb[0]):\n",
        "          p_label = 1\n",
        "        t_label.append(label)\n",
        "        p_labels.append(p_label)\n",
        "\n",
        "        #print(f\"dista: {dista} distb: {distb}\")   \n",
        "  print(f\"Validation accuracy: {classification_report(t_label,p_labels, target_names=['class 0','class 1'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhnOG-nejyX5"
      },
      "source": [
        "## Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCkrbNmfjxWi"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1,output2, label):\n",
        "      # Find the pairwise distance or eucledian distance of two output feature vectors\n",
        "      euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "      # perform contrastive loss calculation with the distance\n",
        "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "      return loss_contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-qqYPFpmLQq"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNM_sJ1EmPzb"
      },
      "outputs": [],
      "source": [
        "# class ViTSiameseNet(nn.Module):\n",
        "#     def __init__(self,verbose=False,width=224,height=224):\n",
        "#         super(ViTSiameseNet, self).__init__()\n",
        "#         self.verbose = verbose\n",
        "#         self.img_width,self.img_height = width,height\n",
        "#         self.vit = vit_small(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "#         self.lin1 = nn.Linear(384, 64)\n",
        "#         self.lin2 = nn.Linear(64, 32)\n",
        "#         self.lin3 = nn.Linear(32, 10)\n",
        "        \n",
        "\n",
        "#     def forward_once(self,x):\n",
        "#         out = self.vit(x)\n",
        "#         #print(x1.shape)\n",
        "#         out = out.reshape(-1,384) \n",
        "#         out = nn.functional.relu(self.lin1(out))\n",
        "#         out = nn.functional.relu(self.lin2(out))\n",
        "#         out = self.lin3(out)\n",
        "        \n",
        "#         return out\n",
        "\n",
        "#     def forward(self, x1, x2):\n",
        "#         out1 = self.forward_once(x1)\n",
        "#         out2 = self.forward_once(x2)\n",
        "#         return out1,out2\n",
        "\n",
        "#     def evaluate(self, x, y):\n",
        "        \n",
        "#         # this can be used later for evalutation\n",
        "        \n",
        "#         m = torch.tensor(1.0, dtype=torch.float32)\n",
        "        \n",
        "#         if type(m) != type(x):\n",
        "#             x = torch.tensor(x, dtype = torch.float32, requires_grad = False)\n",
        "            \n",
        "#         if type(m) != type(y):\n",
        "#             y = torch.tensor(y, dtype = torch.float32, requires_grad = False)\n",
        "        \n",
        "#         x = x.view(-1,1,self.img_width,self.img_height)\n",
        "#         y = y.view(-1,1,self.img_width,self.img_height)\n",
        "        \n",
        "#         with torch.no_grad():\n",
        "            \n",
        "#             out1, out2 = self.forward(x, y)\n",
        "            \n",
        "#             return nn.functional.pairwise_distance(out1, out2)\n",
        "\n",
        "class ViTSiameseNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ViTSiameseNet,self).__init__()\n",
        "        \n",
        "        # A simple two layer convolution followed by three fully connected layers should do\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d( kernel_size=2, stride=2)\n",
        "        self.pool2 = nn.MaxPool2d( kernel_size=3)\n",
        "        \n",
        "        self.lin1 = nn.Linear(20736, 128)\n",
        "        self.lin2 = nn.Linear(128, 256)\n",
        "        self.lin3 = nn.Linear(256, 512)\n",
        "        self.out = nn.Linear(512, 1)\n",
        "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    def forward_once(self,x):\n",
        "        \n",
        "        # forwarding the input through the layers\n",
        "          \n",
        "        out = self.pool1(nn.functional.relu(self.conv1(x)))\n",
        "        out = self.pool2(nn.functional.relu(self.conv2(out)))\n",
        "        \n",
        "        out = out.view(-1,20736)\n",
        "        \n",
        "        out = nn.functional.relu(self.lin1(out))\n",
        "        out = nn.functional.relu(self.lin2(out))\n",
        "        out = self.lin3(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def forward(self, x, y):    \n",
        "        \n",
        "        # doing the forwarding twice so as to obtain the same functions as that of twin networks\n",
        "        \n",
        "        out1 = self.forward_once(x)\n",
        "        out2 = self.forward_once(y)\n",
        "        dis = torch.abs(out1 - out2)\n",
        "        \n",
        "        logits = torch.sigmoid(self.out(dis))\n",
        "        #out = self.cos(out1, out2)\n",
        "        return logits\n",
        "    \n",
        "    def evaluate(self, x, y):\n",
        "        \n",
        "        # this can be used later for evalutation\n",
        "        \n",
        "        m = to.tensor(1.0, dtype=to.float32)\n",
        "        \n",
        "        if type(m) != type(x):\n",
        "            x = to.tensor(x, dtype = to.float32, requires_grad = False)\n",
        "            \n",
        "        if type(m) != type(y):\n",
        "            y = to.tensor(y, dtype = to.float32, requires_grad = False)\n",
        "        \n",
        "        x = x.view(-1,1,28,28)\n",
        "        y = y.view(-1,1,28,28)\n",
        "        \n",
        "        with to.no_grad():\n",
        "            \n",
        "            out1, out2 = self.forward(x, y)\n",
        "            \n",
        "            return nn.functional.pairwise_distance(out1, out2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2__wYg5lSPC"
      },
      "source": [
        "## Train One Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpjENIhvlUXi"
      },
      "outputs": [],
      "source": [
        "def train_Siamese(model,batch_size, num_epochs, Criterion,Optimizer):\n",
        "    train_losses = []\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    train_dataloader = DataLoader(siamdset, shuffle=True, batch_size= batch_size,num_workers=4)\n",
        "    #train_dataloader_mnist = DataLoader(MnistDatasetTrain, shuffle=True, batch_size=  batch_size,num_workers=4)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        correct_batch_prediction_count = 0\n",
        "        start_time = time.time()\n",
        "        for count_idx,data in enumerate(train_dataloader):\n",
        "          img1, img2 , label1, img3, img4, label2 = data\n",
        "          Optimizer.zero_grad()\n",
        "        \n",
        "          # here we obtain the positive pairs' loss as well as the negative pairs' loss\n",
        "          #print(np.array(img1.shape))\n",
        "          output1 = model(img1.cuda(),img2.cuda())\n",
        "          loss_pos = Criterion(output1.reshape(-1,1),label1.cuda())\n",
        "          loss_pos.backward()\n",
        "          running_loss += loss_pos.item()\n",
        "          Optimizer.step()\n",
        "          Optimizer.zero_grad()\n",
        "          output3 = model(img3.cuda(),img4.cuda())\n",
        "          loss_neg = Criterion(output3.reshape(-1,1),label2.cuda())\n",
        "          loss_neg.backward()\n",
        "          running_loss += loss_neg.item()\n",
        "          Optimizer.step()\n",
        "          # print(\"------------\")\n",
        "          # print(nn.functional.pairwise_distance(output1,output2 ))\n",
        "          # print(nn.functional.pairwise_distance(output3,output4 ))\n",
        "          # print(\"------------\")\n",
        "          \n",
        "          \n",
        "          \n",
        "          # the total loss is then computed and back propagated\n",
        "          #print(f\"SImilar {output1} Dissimilar{output3}\")\n",
        "          #loss_contrastive = loss_pos + loss_neg\n",
        "          \n",
        "          \n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_train_loss} Time: {time.time() - start_time}')\n",
        "        if (epoch+1) % 25 == 0:\n",
        "          validationAccuracy_custom(model)\n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/siamese.pth\")\n",
        " \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZW8xU6xlYQS"
      },
      "source": [
        "## Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AaZRCaolfIZ"
      },
      "outputs": [],
      "source": [
        "model = ViTSiameseNet()\n",
        "#summary(model, [(1,224,224),(1,224,224)])\n",
        "model = model.cuda()\n",
        "pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/siamese.pth\"\n",
        "# if os.path.isfile(pretrained_weight_path):\n",
        "model.load_state_dict(torch.load(pretrained_weight_path))\n",
        "params = model.parameters()\n",
        "#params_groups = get_params_groups(model)\n",
        "#optimizer = LARS(params_groups)\n",
        "optimizer = torch.optim.Adam(params,lr = 0.001 )#optim.SGD(params, lr=0.001, momentum=0.5)\n",
        "loss = torch.nn.BCELoss()#ContrastiveLoss()#\n",
        "#optimizer = torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "train_Siamese(model,16,100,loss,optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_ttve6FndBy"
      },
      "source": [
        "## Testing and Evaluation Siamese Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sHHXuwB1xhG"
      },
      "outputs": [],
      "source": [
        "# model = ViTSiameseNet()\n",
        "\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/siamese.pth\"))\n",
        "# model = model.cuda()\n",
        "# def show_image(x,label):\n",
        "#   print(f\"|----{label}---|\")\n",
        "#   temp = x.cpu().detach().numpy()\n",
        "#   pyplot.imshow(temp.reshape(224,224))\n",
        "#   pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-NMhWimvmu0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# test_dataloader = DataLoader(testDataset, shuffle=True, batch_size=1,num_workers=4)\n",
        "# correct_predicted = 0\n",
        "# with torch.no_grad():\n",
        "#   model.eval()\n",
        "#   t_label = []\n",
        "#   p_labels = []\n",
        "#   for data in test_dataloader:\n",
        "#       input_1, label_1, input_2 , label_2, query, label = data\n",
        "#       query_ip_1 = model.evaluate(query.cuda(),input_1.cuda())[0]\n",
        "#       query_ip_2 = model.evaluate(query.cuda(),input_2.cuda())[0]\n",
        "#       # show_image(input_1,'input_1')\n",
        "#       # show_image(label_1,'label_1')\n",
        "#       # show_image(input_2,'input_2')\n",
        "#       # show_image(label_2,'label_2')\n",
        "#       # show_image(query,'query')\n",
        "      \n",
        "\n",
        "#       p_label = 0\n",
        "#       print(f\"query_ip_1: {query_ip_1}query_ip_2: {query_ip_2}\")\n",
        "#       if (query_ip_1 < query_ip_2):\n",
        "#         p_label = 1\n",
        "#       t_label.append(label)\n",
        "#       p_labels.append(p_label)\n",
        "         \n",
        "# print(f\"Correct Prediction: {correct_predicted} Testing accuracy: {classification_report(t_label,p_labels, target_names=['class 0','class 1'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuBsUYreY10O"
      },
      "outputs": [],
      "source": [
        "print(f\"Correct Prediction: {p_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgwXaeJGigKB"
      },
      "source": [
        "# Triplet Siamese Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpU4jnrDEo2f"
      },
      "source": [
        "## Data Loader Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPJkRgBjEo2o"
      },
      "outputs": [],
      "source": [
        "class TripleNetDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "        self.verbose = verbose\n",
        "        self.img_width,self.img_height = width,height\n",
        "        start_time = time.time()\n",
        "        imgs = []\n",
        "        label = []\n",
        "        path = \"/content/drive/MyDrive/Final Project/dataset/train/\"\n",
        "        valid_images = [\".jpg\"]\n",
        "        count =0 \n",
        "        for f in os.listdir(path):\n",
        "            ext = os.path.splitext(f)[1]\n",
        "            if ext.lower() not in valid_images:\n",
        "                continue\n",
        "            if self.verbose:\n",
        "              print(f\"Loaded {count}\")\n",
        "            imgs.append(np.array(Image.open(os.path.join(path,f))))\n",
        "            label.append(f[-5])\n",
        "            count = count + 1\n",
        "            if count >= num_samples:\n",
        "              break\n",
        "        self.images = np.array(imgs)\n",
        "        print(\"|------Dataset Loaded------|\")\n",
        "        print(f\"Total Images {self.images.shape} Labels {len(label)} Time to load: {time.time() - start_time} seconds\")\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        im = Image.fromarray(self.images[idx])\n",
        "        input_1 = detach_cropped_area(im,(0, 10, 52, 52))\n",
        "        label_1 = detach_cropped_area(im,(0, 52, 52, 82))\n",
        "        input_2 = detach_cropped_area(im,(85, 10, 130, 52))\n",
        "        label_2 = detach_cropped_area(im,(85, 52, 130 , 82))\n",
        "        query = detach_cropped_area(im,(180, 35, 230 , 60))\n",
        "        clas = np.random.randint(0,2)\n",
        "\n",
        "        if clas == 0:\n",
        "          img1 = torch.tensor(np.reshape(label_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img2 = torch.tensor(np.reshape(input_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img3 = torch.tensor(np.reshape(input_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "        if clas == 1:\n",
        "          img1 = torch.tensor(np.reshape(label_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img2 = torch.tensor(np.reshape(input_2,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "          img3 = torch.tensor(np.reshape(input_1,(1,self.img_width,self.img_height)), dtype=torch.float32)\n",
        "\n",
        "        return  img1, img2, img3\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return len(self.images)\n",
        "\n",
        "TripleNetdset = TripleNetDataset(5000)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-dmeYpuijto"
      },
      "source": [
        "## Triplet Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmZDi6p2ii1R"
      },
      "outputs": [],
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Triplet loss\n",
        "    Takes embeddings of an anchor sample, a positive sample and a negative sample\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=0.5):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, distance_positive,distance_negative, size_average=False):\n",
        "        # distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)\n",
        "        # distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)\n",
        "        losses = F.relu(distance_positive - distance_negative + self.margin)\n",
        "        return losses.mean() if size_average else losses.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3SAF4FjisJ2"
      },
      "source": [
        "##TripleNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XI4rbHriuLo"
      },
      "outputs": [],
      "source": [
        "class TripletNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embedding_net = vit_small(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "\n",
        "    def forward(self, x1, x2, x3):\n",
        "        output1 = self.embedding_net(x1)\n",
        "        output2 = self.embedding_net(x2)\n",
        "        output3 = self.embedding_net(x3)\n",
        "        dist_a = F.pairwise_distance(output1, output2, 2)\n",
        "        dist_b = F.pairwise_distance(output1, output3, 2)\n",
        "        return dist_a, dist_b, output1,output2,output3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xplM1iVGzAOX"
      },
      "source": [
        "## Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7--9jaPwy_S4"
      },
      "outputs": [],
      "source": [
        "def validationAccuracy(trained_model):\n",
        "  test_dataloader = DataLoader(testDataset, shuffle=True, batch_size=1,num_workers=4)\n",
        "  correct_predicted = 0\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    t_label = []\n",
        "    p_labels = []\n",
        "    for data in test_dataloader:\n",
        "        input_1, label_1, input_2 , label_2, query, label = data\n",
        "        # show_image(input_1,'input_1')\n",
        "        # show_image(label_1,'label_1')\n",
        "        # show_image(input_2,'input_2')\n",
        "        # show_image(label_2,'label_2')\n",
        "        # show_image(query,'query')\n",
        "        #print(f\"query {query.shape}\")\n",
        "        dista, distb, embedded_x, embedded_y, embedded_z = trained_model(label_1.reshape(-1,1,224,224).cuda(),input_1.reshape(-1,1,224,224).cuda(),input_2.reshape(-1,1,224,224).cuda())\n",
        "        p_label = 0\n",
        "        if (dista > distb):\n",
        "          p_label = 1\n",
        "        t_label.append(label)\n",
        "        p_labels.append(p_label)\n",
        "\n",
        "        print(f\"dista: {dista} distb: {distb}\")   \n",
        "  print(f\"Correct Prediction: {correct_predicted} Testing accuracy: {classification_report(t_label,p_labels, target_names=['class 0','class 1'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffbi8TGTj3Zm"
      },
      "source": [
        "## Train One Epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM3S3x_Xj3Zn"
      },
      "outputs": [],
      "source": [
        "def train_Triplet(model,batch_size, num_epochs, Criterion,Optimizer):\n",
        "    train_losses = []\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    train_dataloader = DataLoader(TripleNetdset, shuffle=True, batch_size= batch_size,num_workers=4)\n",
        "    for epoch in range(num_epochs):\n",
        "        if (epoch) % 5 == 0:\n",
        "          validationAccuracy(model)\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        correct_batch_prediction_count = 0\n",
        "        start_time = time.time()\n",
        "        for data in train_dataloader:\n",
        "          img1, img2, img3 = data\n",
        "          Optimizer.zero_grad()\n",
        "        \n",
        "          # compute output\n",
        "          dista, distb, embedded_x, embedded_y, embedded_z = model(img1.cuda(),img2.cuda(),img3.cuda())\n",
        "          # 1 means, dista should be larger than distb\n",
        "          target = torch.FloatTensor(dista.size()).fill_(1).cuda()\n",
        "          loss_triplet = Criterion(dista, distb)\n",
        "          avg_train_loss = running_loss / batch_size\n",
        "          train_losses.append(avg_train_loss)\n",
        "          loss_embedd = embedded_x.norm(2) + embedded_y.norm(2) + embedded_z.norm(2)\n",
        "          loss = loss_triplet + 0.001 * loss_embedd\n",
        "          loss.backward()\n",
        "          Optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_train_loss} Training Time: {time.time() - start_time} ')\n",
        "        \n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/triplet.pth\")\n",
        " \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoLXjOEujb4B"
      },
      "source": [
        "## Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsV_wvo9jeTT"
      },
      "outputs": [],
      "source": [
        "model = TripletNet()\n",
        "model = model.cuda()\n",
        "pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/triplet.pth\"\n",
        "# if os.path.isfile(pretrained_weight_path):\n",
        "#model.load_state_dict(torch.load(pretrained_weight_path))\n",
        "params = model.parameters()\n",
        "#params_groups = get_params_groups(model)\n",
        "#optimizer = LARS(params_groups)\n",
        "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.5)\n",
        "loss = TripletLoss()#torch.nn.MarginRankingLoss(margin = 2)\n",
        "#optimizer = torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "train_Triplet(model,16,30,loss,optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWIRcBFNmUjL"
      },
      "source": [
        "## Testing and Evaluation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mym42WYBJ72s"
      },
      "outputs": [],
      "source": [
        "model = TripletNet()\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/triplet.pth\"))\n",
        "model = model.cuda()\n",
        "def show_image(x,label):\n",
        "  print(f\"|----{label}---|\")\n",
        "  temp = x.cpu().detach().numpy()\n",
        "  pyplot.imshow(temp.reshape(224,224))\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twMPAfqjmUjU"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_dataloader = DataLoader(testDataset, shuffle=True, batch_size=1,num_workers=4)\n",
        "correct_predicted = 0\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  t_label = []\n",
        "  p_labels = []\n",
        "  for data in test_dataloader:\n",
        "      input_1, label_1, input_2 , label_2, query, label = data\n",
        "      # show_image(input_1,'input_1')\n",
        "      # show_image(label_1,'label_1')\n",
        "      # show_image(input_2,'input_2')\n",
        "      # show_image(label_2,'label_2')\n",
        "      # show_image(query,'query')\n",
        "      #print(f\"query {query.shape}\")\n",
        "      dista, distb, embedded_x, embedded_y, embedded_z = model(query.reshape(-1,1,224,224).cuda(),input_1.reshape(-1,1,224,224).cuda(),input_2.reshape(-1,1,224,224).cuda())\n",
        "      p_label = 0\n",
        "      if (query_ip_1 <query_ip_2):\n",
        "        p_label = 1\n",
        "      t_label.append(label)\n",
        "      p_labels.append(p_label)\n",
        "\n",
        "    \n",
        "print(f\"Correct Prediction: {correct_predicted} Testing accuracy: {classification_report(t_label,p_labels, target_names=['class 0','class 1'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qJlkXN1o7M0"
      },
      "source": [
        "# Relation Nework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7vOpG0stJMj"
      },
      "source": [
        "## Train One Epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVfTJp0pRvT"
      },
      "source": [
        "## Relation Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_xWYb_zo9R6"
      },
      "outputs": [],
      "source": [
        "# class RelationNetwork(nn.Module):\n",
        "#   \"\"\"docstring for RelationNetwork\"\"\"\n",
        "#   def __init__(self):\n",
        "#       super(RelationNetwork, self).__init__()\n",
        "#       self.embedding_net = vit_small(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "#       self.layer1 = nn.Sequential(\n",
        "#                       nn.Conv2d(384 * 2,384,kernel_size=3,padding=1),\n",
        "#                       nn.BatchNorm2d(384, momentum=1, affine=True),\n",
        "#                       nn.ReLU(),\n",
        "#                       nn.MaxPool2d(2))\n",
        "#       self.layer2 = nn.Sequential(\n",
        "#                       nn.Conv2d(384,384,kernel_size=3,padding=1),\n",
        "#                       nn.BatchNorm2d(384, momentum=1, affine=True),\n",
        "#                       nn.ReLU(),\n",
        "#                       nn.MaxPool2d(2))\n",
        "#       self.fc1 = nn.Linear(384 *2, 512)\n",
        "#       self.batch_norm_1 = nn.BatchNorm1d(512)\n",
        "#       self.dropout_1 = nn.Dropout(p=0.2)\n",
        "#       self.fc2 = nn.Linear(512, 1024)\n",
        "#       self.batch_norm_2 = nn.BatchNorm1d(1024)\n",
        "#       self.fcOut = nn.Linear(1024, 1)\n",
        "\n",
        "\n",
        "#   def forward(self,query,input):\n",
        "#       # input_embedding = self.embedding_net(input).reshape(-1)\n",
        "#       # query_embedding = self.embedding_net(query).reshape(-1)\n",
        "#       tuple = (query, input )\n",
        "#       out = torch.cat(tuple).reshape(-1)\n",
        "#       # print(f\"query {query} \")\n",
        "#       # print(f\"input {input}\")\n",
        "#       # print(f\"query sd {torch.std(query)} \")\n",
        "#       # print(f\"input sd {torch.std(input)}\")\n",
        "      \n",
        "#       #out = abs(input - query)\n",
        "#       # out = self.fc1(input_query)\n",
        "#       # out = self.layer2(out)\n",
        "#       # out = out.view(out.size(0),-1)\n",
        "#       out = self.fc1(out)\n",
        "#       out = F.tanh(out)\n",
        "#       #out = self.dropout_1(out)\n",
        "#       out = self.fc2(out)\n",
        "#       out = F.tanh(out)\n",
        "#       out = torch.sigmoid(self.fcOut(out))\n",
        "      \n",
        "#       return out\n",
        "class RelationNetwork(nn.Module):\n",
        "    \"\"\"docstring for RelationNetwork\"\"\"\n",
        "    def __init__(self):\n",
        "        super(RelationNetwork, self).__init__()\n",
        "        self.layer1 = vit_base(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "        self.fc1 = nn.Linear(384*2,512)\n",
        "        self.fc1_bn=nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512,1024)\n",
        "        self.fc2_bn=nn.BatchNorm1d(1024)\n",
        "        self.fc3 = nn.Linear(1024,1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self,query, input):\n",
        "        tuple = (query, input )\n",
        "        x = torch.cat(tuple).reshape(30,-1)\n",
        "        #out = self.layer1(x)\n",
        "        #out = self.layer2(out)\n",
        "        #out = out.view(out.size(0),-1)\n",
        "        out = self.dropout(F.relu(self.fc1_bn(self.fc1(x))))\n",
        "        out = self.dropout(F.relu(self.fc2_bn(self.fc2(out))))\n",
        "        out = torch.sigmoid(self.fc3(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzjYaDGwtKwz"
      },
      "outputs": [],
      "source": [
        "def train_RelationNet(feature_encoder,model, images,batch_size, num_epochs, criterion,optimizer,feature_encoder_optimizer):\n",
        "    train_losses = []\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    images = np.array(images).reshape(-1,batch_size,80,250)\n",
        "    lambda1 = lambda epoch: epoch / 100 \n",
        "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lambda1)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        correct_batch_prediction_count = 0\n",
        "        start_time = time.time()\n",
        "        for batch in  range(images.shape[0]):\n",
        "          img_1 = []\n",
        "          img_2 = [] \n",
        "          main_labels = []\n",
        "          #print(f\"Training on batch {batch} / {images.shape[0]}\")\n",
        "          label_1_batch=[]\n",
        "          label_2_batch=[]\n",
        "          input_1_batch=[]\n",
        "          input_2_batch=[]\n",
        "          main_input_1 = []\n",
        "          main_input_2 = []\n",
        "          \n",
        "          output2=[]\n",
        "          output3=[]\n",
        "          output = []\n",
        "          for i in range(batch_size):\n",
        "            #print(f\"Generating sample {i}\")\n",
        "            pixels = images[batch][i]\n",
        "            im = Image.fromarray(pixels)\n",
        "            #pyplot.imshow(pixels)\n",
        "            #pyplot.show()\n",
        "            input_1 = detach_cropped_area(im,(0, 10, 52, 52))\n",
        "            label_1 = detach_cropped_area(im,(0, 52, 52, 82))\n",
        "            input_2 = detach_cropped_area(im,(85, 10, 130, 52))\n",
        "            label_2 = detach_cropped_area(im,(85, 52, 130 , 82))\n",
        "            label_1_batch.append(label_1)\n",
        "            label_2_batch.append(label_2)\n",
        "            input_1_batch.append(input_1)\n",
        "            input_2_batch.append(input_2)\n",
        "            random_label = random.randint(0, 1)\n",
        "            main_input_1.append(label_1)\n",
        "            if (random_label == 0):\n",
        "              main_input_2.append(input_1)              \n",
        "            else:\n",
        "              main_input_2.append(input_2)\n",
        "            main_labels.append(random_label)\n",
        "          main_input_1 = feature_encoder(torch.Tensor(main_input_1).reshape(images.shape[1],1,224,224).cuda())\n",
        "          main_input_2 = feature_encoder(torch.Tensor(main_input_2).reshape(images.shape[1],1,224,224).cuda())\n",
        "          # label_1_batch = torch.Tensor(label_1_batch).reshape(images.shape[1],1,224,224).cuda()\n",
        "          # label_2_batch = torch.Tensor(label_2_batch).reshape(images.shape[1],1,224,224).cuda()\n",
        "          # input_1_batch = torch.Tensor(input_1_batch).reshape(images.shape[1],1,224,224).cuda()\n",
        "          # input_2_batch = torch.Tensor(input_2_batch).reshape(images.shape[1],1,224,224).cuda()\n",
        "          # label_1_encoded = feature_encoder(label_1_batch)\n",
        "          # label_2_encoded = feature_encoder(label_2_batch)\n",
        "          # input_1_encoded = feature_encoder(input_1_batch)\n",
        "          # input_2_encoded = feature_encoder(input_2_batch)\n",
        "          # #print(f\"label 1 shape {label_1_encoded.shape}\")\n",
        "          # input_1 = torch.tensor([]).cuda()\n",
        "          # input_2 = torch.tensor([]).cuda()\n",
        "          # for j in range(batch_size):\n",
        "          #   random_label = random.randint(0, 1)\n",
        "          #   input_1 = torch.cat((input_1,label_1_encoded[j]))\n",
        "          #   if (random_label == 0):\n",
        "          #     input_2 = torch.cat((input_2,input_1_encoded[j]))              \n",
        "          #   else:\n",
        "          #     input_2 = torch.cat((input_2,input_2_encoded[j]))\n",
        "          #   labels.append(random_label)\n",
        "          # input_1 = input_1.reshape(batch_size,384)\n",
        "          # input_2 = input_2.reshape(batch_size,384) \n",
        "          #print(f\"input {main_input_1.shape} \")  \n",
        "          output = model(main_input_1,main_input_2).reshape(-1)\n",
        "          main_labels = torch.Tensor(main_labels).reshape(-1).cuda()\n",
        "          #print(f\"output {output.shape} {output}\")\n",
        "          #print(f\"Labels {labels.shape} {labels}\")\n",
        "    #         #query = torch.Tensor(np.array(detach_cropped_area(im,(180, 35, 230 , 60)).reshape(1,1,224,224))).cuda()\n",
        "    #         random_label = random.randint(0, 1)\n",
        "    #         #if (random_label == 1):\n",
        "    #         label_1_encoded = feature_encoder(label_1)\n",
        "    #         input_1_encoded = feature_encoder(input_1)\n",
        "    #         input_2_encoded = feature_encoder(input_2)\n",
        "    #         relation_1 = model(label_1_encoded,input_1_encoded)\n",
        "    #         labels.append(1)\n",
        "    #         relation_2 = model(label_1_encoded,input_2_encoded)\n",
        "    #         labels.append(0)\n",
        "    #         # else:\n",
        "    #         #     relation_1 = model(label_2,input_1)\n",
        "    #         #     labels.append(0)\n",
        "    #         #     relation_2 = model(label_2,input_2)\n",
        "    #         #     labels.append(1)\n",
        "    #         output1.append(relation_1)\n",
        "    #         output1.append(relation_2)          \n",
        "    #       labels = torch.unsqueeze(torch.Tensor(labels).type(torch.FloatTensor),1).reshape(-1).cuda()    \n",
        "    #       output1 = torch.cat(output1).reshape(-1)    \n",
        "    #       print(f\"output1 {output1} {torch.std(output1)}\")\n",
        "    #       print(f\"Labels {labels} {torch.std(labels)}\")\n",
        "          loss = criterion(output,torch.tensor(main_labels).type(torch.FloatTensor).cuda())\n",
        "\n",
        "          #print(f\"Loss {loss}\")\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          feature_encoder_optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          feature_encoder_optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          #scheduler.step()\n",
        "          # for i in range(len(outputs)):\n",
        "          #   if true_labels[i] == 0 and torch.round(outputs[i]) == 0:\n",
        "          #     correct_batch_prediction_count += 1\n",
        "          #   elif true_labels[i] == 1 and torch.round(outputs[i]) >= 1:\n",
        "          #     correct_batch_prediction_count += 1\n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_train_loss},Correctly Predicted: {correct_batch_prediction_count} Train Accuracy: {correct_batch_prediction_count/(images.shape[0] * images.shape[1])} Time: {time.time() - start_time}')\n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/relationNet.pth\")\n",
        "        torch.save(feature_encoder.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/feature_encoder.pth\")\n",
        " \n",
        "    return train_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw4DxSJ1u47b"
      },
      "source": [
        "## Main Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KprP45y_u6ap"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "feature_encoder = vit_small(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "feature_encoder = feature_encoder.cuda()\n",
        "model = RelationNetwork()\n",
        "model = model.cuda()\n",
        "#pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/relationNet.pth\"\n",
        "#if path.exists(pretrained_weight_path):\n",
        "#model.load_state_dict(torch.load(pretrained_weight_path))\n",
        "#params_groups = get_params_groups(model)\n",
        "#optimizer = LARS(params_groups)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "feature_encoder_optimizer = optim.SGD(feature_encoder.parameters(), lr=0.01, momentum=0.9)\n",
        "#torch.optim.Adamax(feature_encoder.parameters(), lr=0.1, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "loss = nn.MSELoss().cuda()\n",
        "#optimizer = torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "train_RelationNet(feature_encoder,model,images,30,100,loss,optimizer,feature_encoder_optimizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ydsu6VoFeLj"
      },
      "source": [
        "## Testing and Evaluation RelationNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfO1Qw4OFeLj"
      },
      "outputs": [],
      "source": [
        "def detach_cropped_area(im,coods,debug = False):\n",
        "  im_width = 54\n",
        "  im_height = 54\n",
        "  area = coods\n",
        "  cropped_img = im.crop(area)\n",
        "  newimage = cropped_img.resize((224,224))\n",
        "  #numpy_array = np.asarray(cropped_img)\n",
        "  # if debug == True && False:\n",
        "  #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "  #   pyplot.show()\n",
        "  #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "  # if debug == True:\n",
        "  #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  # pyplot.imshow(newimage)\n",
        "  # pyplot.show()\n",
        "  return newimage\n",
        "\n",
        "\n",
        "def eval(model, num_testing_samples):\n",
        "    correct_prediction_count = 0\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        count = 0\n",
        "        img_1 = []\n",
        "        img_2 = [] \n",
        "        labels = []\n",
        "        for i in range(num_testing_samples):\n",
        "          #print(f\"Generating sample {i}\")\n",
        "          pixels,input_digits,selected_digit = environment.reset()\n",
        "          im = Image.fromarray(pixels)\n",
        "          pyplot.imshow(pixels)\n",
        "          pyplot.show()\n",
        "          input_1 = torch.Tensor(np.array(detach_cropped_area(im,(0, 10, 52, 52))).reshape(1,1,224,224)).cuda()\n",
        "          label_1 = torch.Tensor(np.array(detach_cropped_area(im,(0, 52, 52, 82))).reshape(1,1,224,224)).cuda()\n",
        "          input_2 = torch.Tensor(np.array(detach_cropped_area(im,(85, 10, 130, 52))).reshape(1,1,224,224)).cuda()\n",
        "          label_2 = torch.Tensor(np.array(detach_cropped_area(im,(85, 52, 130 , 82))).reshape(1,1,224,224)).cuda()\n",
        "          query = torch.Tensor(np.array(detach_cropped_area(im,(180, 35, 230 , 60))).reshape(1,1,224,224)).cuda()\n",
        "          label_1_encoded = feature_encoder(label_1)\n",
        "          input_1_encoded = feature_encoder(input_1)\n",
        "          input_2_encoded = feature_encoder(input_2)\n",
        "          label_2_encoded = feature_encoder(label_2)\n",
        "          query_encoded = feature_encoder(query)\n",
        "          relation_1 = model(label_1_encoded,input_1_encoded)\n",
        "          relation_2 = model(label_2_encoded,input_2_encoded)\n",
        "          relation_3 = model(query_encoded,input_1_encoded)\n",
        "          relation_4 = model(query_encoded,input_2_encoded)\n",
        "          print(f\"Relation_1 label_1 and input_1 {relation_1}\")\n",
        "          print(f\"Relation_2 label_2 and input_2 {relation_2}\")\n",
        "          print(f\"Relation_3 query and input_1 {relation_3}\")\n",
        "          print(f\"Relation_4 query and input_2 {relation_4}\")\n",
        "          pyplot.imshow(Image.fromarray(input_1.cpu().numpy().reshape(224,224)))\n",
        "          pyplot.show()\n",
        "          pyplot.imshow(Image.fromarray(label_1.cpu().numpy().reshape(224,224)))\n",
        "          pyplot.show()\n",
        "          pyplot.imshow(Image.fromarray(input_2.cpu().numpy().reshape(224,224)))\n",
        "          pyplot.show()\n",
        "          pyplot.imshow(Image.fromarray(label_2.cpu().numpy().reshape(224,224)))\n",
        "          pyplot.show()\n",
        "          pyplot.imshow(Image.fromarray(query.cpu().numpy().reshape(224,224)))\n",
        "          pyplot.show()\n",
        "          #output_3,output_4 = model(torch.Tensor(np.array(query).reshape(1,1,224,224)),torch.Tensor(np.array(input_2).reshape(1,1,224,224)))\n",
        "          # output_3 = model(torch.Tensor(np.array(input_2).reshape(1,1,54,54)).cuda()).cpu()\n",
        "          # output_4 = model(torch.Tensor(np.array(label_1).reshape(1,1,54,54)).cuda()).cpu()      \n",
        "          # output_5 = model(torch.Tensor(np.array(label_2).reshape(1,1,54,54)).cuda()).cpu()\n",
        "          # print(f\"Query and Input 1 Eculidina Distance: {F.pairwise_distance(output_1, output_2)}\")         \n",
        "          # print(f\"Query and Input 2 Eculidina Distance: {F.pairwise_distance(output_1, output_3)}\")  \n",
        "          # print(f\"Query and Input 1 Distance: {(output_1 - output_2).pow(2).sum(1)}\")  \n",
        "          # print(f\"Query and Input 1 Distance: {(output_1 - output_3).pow(2).sum(1)}\")  \n",
        "          #print(f\"Query and Input 2 similarity: {spatial.distance.cosine(output_1, output_3)}\")         \n",
        "          # print(f\"Query and Label 2 similarity: {spatial.distance.cosine(output_1, output_5)}\")  \n",
        "          # print(f\"Input 1 and Label 1 similarity: {spatial.distance.cosine(output_2, output_4)}\")\n",
        "          # print(f\"Input 2 and Label 2 similarity: {spatial.distance.cosine(output_3, output_5)}\")\n",
        "          # print(f\"Input 1 and Label 2 similarity: {spatial.distance.cosine(output_2, output_5)}\")\n",
        "          # print(f\"Input 2 and Label 1 similarity: {spatial.distance.cosine(output_3, output_4)}\")\n",
        "          # if (output_1 - output_2).pow(2).sum(1) >  (output_1 - output_3).pow(2).sum(1) :\n",
        "          #   prediction = 1\n",
        "          # else:\n",
        "          #   prediction = 0\n",
        "          # # #print(input_digits.index(selected_digit))\n",
        "          # # print(f\"Labels {input_digits.index(selected_digit)}\")\n",
        "          # # print(f\"prediction {prediction}\")\n",
        "          # if prediction == input_digits.index(selected_digit):\n",
        "          #   correct_prediction_count += 1\n",
        "          # print(f\"query Output_1 : {output_1}\")\n",
        "          # print(f\"input_1 Output_2 : {output_2}\")\n",
        "          # print(f\"input_2 Output_3 : {output_3}\")\n",
        "          # print(f\"Output_4 : {output_4}\")\n",
        "    #print(f\"Correct Prediction: {correct_prediction_count} Testing accuracy: {correct_prediction_count / num_testing_samples}\")\n",
        "model = RelationNetwork()\n",
        "model = model.cuda()\n",
        "pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/relationNet.pth\"\n",
        "model.load_state_dict(torch.load(pretrained_weight_path))\n",
        "eval(model,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iO0s4noika0"
      },
      "outputs": [],
      "source": [
        "def detach_cropped_area(im,coods,debug = False):\n",
        "  im_width = 224\n",
        "  im_height = 224\n",
        "  area = coods\n",
        "  cropped_img = im.crop(area)\n",
        "  newimage = cropped_img.resize((im_width,im_height))\n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  scaler.fit(newimage)\n",
        "  newimage = scaler.transform(newimage)\n",
        "  #numpy_array = np.asarray(cropped_img)\n",
        "  # if debug == True && False:\n",
        "  #   print(f\"Before Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  # print(newimage)\n",
        "  # pyplot.imshow(newimage)\n",
        "  # pyplot.show()\n",
        "  #numpy_array = np.pad(numpy_array, [(0,im_height - numpy_array.shape[0]),(0, im_width - numpy_array.shape[1])], mode='constant')\n",
        "  # if debug == True:\n",
        "  #   print(f\"After Padding Coods: {coods} Shape: {numpy_array.shape}\")\n",
        "  #   pyplot.imshow(Image.fromarray(numpy_array))\n",
        "  #   pyplot.show()\n",
        "  return newimage\n",
        "def eval(num_epochs,batch_size):\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    lambda1 = lambda epoch: epoch / 100 \n",
        "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lambda1)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct_predicted = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            running_loss = 0.0\n",
        "            model.train()\n",
        "            #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "            correct_batch_prediction_count = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "            #print(f\"Training on batch {batch} / {images.shape[0]}\")\n",
        "            label_1_batch=[]\n",
        "            label_2_batch=[]\n",
        "            input_1_batch=[]\n",
        "            input_2_batch=[]\n",
        "            query_batch = []\n",
        "            main_label_1 = []\n",
        "            main_input_1 = []\n",
        "            main_label_2 = []\n",
        "            main_input_2 = [] \n",
        "            main_query = [] \n",
        "            main_labels = []\n",
        "            output2=[]\n",
        "            output3=[]\n",
        "            output = []\n",
        "\n",
        "            selected_digit_array = []\n",
        "            \n",
        "            for i in range(batch_size):\n",
        "              #print(f\"Generating sample {i}\")\n",
        "              pixels,input_digits,selected_digit = environment.reset()\n",
        "              im = Image.fromarray(pixels)\n",
        "              # pyplot.imshow(pixels)\n",
        "              # pyplot.show()\n",
        "              input_1 = detach_cropped_area(im,(0, 10, 52, 52))\n",
        "              label_1 = detach_cropped_area(im,(0, 52, 52, 82))\n",
        "              input_2 = detach_cropped_area(im,(85, 10, 130, 52))\n",
        "              label_2 = detach_cropped_area(im,(85, 52, 130 , 82))\n",
        "              query = detach_cropped_area(im,(180, 35, 230 , 60))\n",
        "              label_1_batch.append(label_1)\n",
        "              label_2_batch.append(label_2)\n",
        "              input_1_batch.append(input_1)\n",
        "              input_2_batch.append(input_2)\n",
        "              query_batch.append(query)\n",
        "              selected_digit_array.append(input_digits.index(selected_digit))\n",
        "              # random_label = random.randint(0, 1)\n",
        "              # main_input_1.append(label_1)\n",
        "              # main_input_2.append(input_1) \n",
        "              # if (random_label == 0):\n",
        "              #   main_input_2.append(input_1)              \n",
        "              # else:\n",
        "              #   main_input_2.append(input_2)\n",
        "              # main_labels.append(random_label)\n",
        "            main_label_1 = feature_encoder(torch.Tensor(label_1_batch).reshape(batch_size,1,224,224).cuda())\n",
        "            main_label_2 = feature_encoder(torch.Tensor(label_2_batch).reshape(batch_size,1,224,224).cuda())\n",
        "            main_input_1 = feature_encoder(torch.Tensor(input_1_batch).reshape(batch_size,1,224,224).cuda())\n",
        "            main_input_2 = feature_encoder(torch.Tensor(input_2_batch).reshape(batch_size,1,224,224).cuda())\n",
        "            main_query = feature_encoder(torch.Tensor(query_batch).reshape(batch_size,1,224,224).cuda())\n",
        "            output_1 = model(main_query,main_input_1).reshape(-1).cpu().detach().numpy()\n",
        "            #print(f\"output label 1 input 1{output_1.shape} {output_1}\")\n",
        "            output_2 = model(main_query,main_input_2).reshape(-1).cpu().detach().numpy()\n",
        "            #print(f\"output label 1 input 2{output_2.shape} {output_2}\")\n",
        "            \n",
        "            #print(selected_digit_array)\n",
        "            for i in range(len(output_1)):\n",
        "              if output_1[i] < output_2[i] :\n",
        "                #(f\"Prediction {0} label {selected_digit_array[i]}\")\n",
        "                if selected_digit_array[i] == 0:\n",
        "                  correct_predicted += 1\n",
        "              else:\n",
        "                #print(f\"Prediction {1} label {selected_digit_array[i]}\")\n",
        "                if selected_digit_array[i] == 1:\n",
        "                  correct_predicted += 1\n",
        "        print(f\"correct_predicted  {correct_predicted } test accuracy: {correct_predicted / (num_epochs * batch_size)}\")\n",
        "eval(10,30)\n",
        "eval(10,30)\n",
        "eval(10,30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOZvwm9Tlfhi"
      },
      "source": [
        "# Attention Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UpeD3xeliU7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import skimage.io\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    for c in range(3):\n",
        "        image[:, :, c] = image[:, :, c] * (1 - alpha * mask) + alpha * mask * color[c] * 255\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_colors(N, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors\n",
        "\n",
        "\n",
        "def display_instances(image, mask, fname=\"test\", figsize=(5, 5), blur=False, contour=True, alpha=0.5):\n",
        "    fig = plt.figure(figsize=figsize, frameon=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    N = 1\n",
        "    mask = mask[None, :, :]\n",
        "    # Generate random colors\n",
        "    colors = random_colors(N)\n",
        "\n",
        "    # Show area outside image boundaries.\n",
        "    height, width = image.shape[:2]\n",
        "    margin = 0\n",
        "    ax.set_ylim(height + margin, -margin)\n",
        "    ax.set_xlim(-margin, width + margin)\n",
        "    ax.axis('off')\n",
        "    masked_image = image.astype(np.uint32).copy()\n",
        "    for i in range(N):\n",
        "        color = colors[i]\n",
        "        _mask = mask[i]\n",
        "        if blur:\n",
        "            _mask = cv2.blur(_mask,(10,10))\n",
        "        # Mask\n",
        "        masked_image = apply_mask(masked_image, _mask, color, alpha)\n",
        "        # Mask Polygon\n",
        "        # Pad to ensure proper polygons for masks that touch image edges.\n",
        "        if contour:\n",
        "            padded_mask = np.zeros((_mask.shape[0] + 2, _mask.shape[1] + 2))\n",
        "            padded_mask[1:-1, 1:-1] = _mask\n",
        "            contours = find_contours(padded_mask, 0.5)\n",
        "            for verts in contours:\n",
        "                # Subtract the padding and flip (y, x) to (x, y)\n",
        "                verts = np.fliplr(verts) - 1\n",
        "                p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
        "                ax.add_patch(p)\n",
        "    ax.imshow(masked_image.astype(np.uint8), aspect='auto')\n",
        "    fig.savefig(fname)\n",
        "    print(f\"{fname} saved.\")\n",
        "    return\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = {\n",
        "        \"arch\":\"vit_small\", #help='Architecture (support only ViT atm).'\n",
        "        \"patch_size\":16, #help='Patch resolution of the model.\n",
        "        \"pretrained_weights\":'checkpoint.pth', #help=\"Path to pretrained weights to load.\"\n",
        "        \"checkpoint_key\":\"teacher\", #help='Key to use in the checkpoint (example: \"teacher\")'\n",
        "        \"image_path\":\"test_img_3.jpg\",#help=\"Path of the image to load.\"\n",
        "        \"image_size\":(480,480),#help=\"Resize image.\"\n",
        "        \"output_dir\":'.',#help='Path where to save visualizations.'\n",
        "        \"threshold\":None, #help=\"\"\"We visualize masks obtained by thresholding the self-attention maps to keep xx% of the mass.\"\"\"\n",
        "    } \n",
        "   \n",
        "\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    # build model\n",
        "    model = vit_small(patch_size=args[\"patch_size\"], num_classes=0)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    if os.path.isfile(args[\"pretrained_weights\"]):\n",
        "        state_dict = torch.load(args[\"pretrained_weights\"], map_location=\"cpu\")\n",
        "        if args[\"checkpoint_key\"] is not None and args[\"checkpoint_key\"] in state_dict:\n",
        "            print(f\"Take key {args['checkpoint_key']} in provided checkpoint dict\")\n",
        "            state_dict = state_dict[args[\"checkpoint_key\"]]\n",
        "        # remove `module.` prefix\n",
        "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "        # remove `backbone.` prefix induced by multicrop wrapper\n",
        "        state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
        "        msg = model.load_state_dict(state_dict, strict=False)\n",
        "        print('Pretrained weights found at {} and loaded with msg: {}'.format(args['pretrained_weights'], msg))\n",
        "    else:\n",
        "        print(\"Please use the `--pretrained_weights` argument to indicate the path of the checkpoint to evaluate.\")\n",
        "        url = None\n",
        "        if args[\"arch\"] == \"vit_small\" and args[\"patch_size\"] == 16:\n",
        "            url = \"dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\"\n",
        "        elif args[\"arch\"] == \"vit_small\" and args[\"patch_size\"] == 8:\n",
        "            url = \"dino_deitsmall8_300ep_pretrain/dino_deitsmall8_300ep_pretrain.pth\"  # model used for visualizations in our paper\n",
        "        elif args[\"arch\"] == \"vit_base\" and args[\"patch_size\"] == 16:\n",
        "            url = \"dino_vitbase16_pretrain/dino_vitbase16_pretrain.pth\"\n",
        "        elif args[\"arch\"] == \"vit_base\" and args[\"patch_size\"] == 8:\n",
        "            url = \"dino_vitbase8_pretrain/dino_vitbase8_pretrain.pth\"\n",
        "        if url is not None:\n",
        "            print(\"Since no pretrained weights have been provided, we load the reference pretrained DINO weights.\")\n",
        "            state_dict = torch.hub.load_state_dict_from_url(url=\"https://dl.fbaipublicfiles.com/dino/\" + url)\n",
        "            model.load_state_dict(state_dict, strict=True)\n",
        "        else:\n",
        "            print(\"There is no reference weights available for this model => We use random weights.\")\n",
        "\n",
        "    # open image\n",
        "    if args[\"image_path\"] is None:\n",
        "        # user has not specified any image - we use our own image\n",
        "        print(\"Please use the `--image_path` argument to indicate the path of the image you wish to visualize.\")\n",
        "        print(\"Since no image path have been provided, we take the first image in our paper.\")\n",
        "        response = requests.get(\"https://dl.fbaipublicfiles.com/dino/img.png\")\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img = img.convert('RGB')\n",
        "    elif os.path.isfile(args[\"image_path\"]):\n",
        "        with open(args[\"image_path\"], 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert('L')\n",
        "    else:\n",
        "        print(f\"Provided image path {args['image_path']} is non valid.\")\n",
        "        sys.exit(1)\n",
        "    transform = pth_transforms.Compose([\n",
        "        pth_transforms.Resize(args[\"image_size\"]),\n",
        "        pth_transforms.ToTensor(),\n",
        "        #pth_transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "    img = transform(img)\n",
        "\n",
        "    # make the image divisible by the patch size\n",
        "    w, h = img.shape[1] - img.shape[1] % args[\"patch_size\"], img.shape[2] - img.shape[2] % args[\"patch_size\"]\n",
        "    img = img[:, :w, :h].unsqueeze(0)\n",
        "\n",
        "    w_featmap = img.shape[-2] // args[\"patch_size\"]\n",
        "    h_featmap = img.shape[-1] // args[\"patch_size\"]\n",
        "\n",
        "    attentions = model.get_last_selfattention(img.to(device))\n",
        "\n",
        "    nh = attentions.shape[1] # number of head\n",
        "\n",
        "    # we keep only the output patch attention\n",
        "    attentions = attentions[0, :, 0, 1:].reshape(nh, -1)\n",
        "\n",
        "    if args[\"threshold\"] is not None:\n",
        "        # we keep only a certain percentage of the mass\n",
        "        val, idx = torch.sort(attentions)\n",
        "        val /= torch.sum(val, dim=1, keepdim=True)\n",
        "        cumval = torch.cumsum(val, dim=1)\n",
        "        th_attn = cumval > (1 - args[\"threshold\"])\n",
        "        idx2 = torch.argsort(idx)\n",
        "        for head in range(nh):\n",
        "            th_attn[head] = th_attn[head][idx2[head]]\n",
        "        th_attn = th_attn.reshape(nh, w_featmap, h_featmap).float()\n",
        "        # interpolate\n",
        "        th_attn = nn.functional.interpolate(th_attn.unsqueeze(0), scale_factor=args[\"patch_size\"], mode=\"nearest\")[0].cpu().numpy()\n",
        "\n",
        "    attentions = attentions.reshape(nh, w_featmap, h_featmap)\n",
        "    attentions = nn.functional.interpolate(attentions.unsqueeze(0), scale_factor=args[\"patch_size\"], mode=\"nearest\")[0].cpu().numpy()\n",
        "\n",
        "    # save attentions heatmaps\n",
        "    os.makedirs(args[\"output_dir\"], exist_ok=True)\n",
        "    torchvision.utils.save_image(torchvision.utils.make_grid(img, normalize=True, scale_each=True), os.path.join(args[\"output_dir\"], \"img.png\"))\n",
        "    for j in range(nh):\n",
        "        fname = os.path.join(args[\"output_dir\"], \"attn-head\" + str(j) + \".png\")\n",
        "        plt.imsave(fname=fname, arr=attentions[j], format='png')\n",
        "        print(f\"{fname} saved.\")\n",
        "\n",
        "    if args[\"threshold\"] is not None:\n",
        "        image = skimage.io.imread(os.path.join(args[\"output_dir\"], \"img.png\"))\n",
        "        for j in range(nh):\n",
        "            display_instances(image, th_attn[j], fname=os.path.join(args[\"output_dir\"], \"mask_th\" + str(args[\"threshold\"]) + \"_head\" + str(j) +\".png\"), blur=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdC2c8EFTaqG"
      },
      "source": [
        "# Reference Code Relation Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbJIB4H9TgrW"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------\n",
        "# Project: Learning to Compare: Relation Network for Few-Shot Learning\n",
        "# Date: 2017.9.21\n",
        "# Author: Flood Sung\n",
        "# All Rights Reserved\n",
        "#-------------------------------------\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np\n",
        "import task_generator as tg\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "FEATURE_DIM = 64\n",
        "RELATION_DIM = 8\n",
        "CLASS_NUM = 5\n",
        "SAMPLE_NUM_PER_CLASS = 5\n",
        "BATCH_NUM_PER_CLASS = 15\n",
        "EPISODE = 1000000\n",
        "TEST_EPISODE = 1000\n",
        "LEARNING_RATE = 0.001\n",
        "GPU = 0\n",
        "HIDDEN_UNIT = 10\n",
        "\n",
        "class CNNEncoder(nn.Module):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(1,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=0),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU())\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        #out = out.view(out.size(0),-1)\n",
        "        return out # 64\n",
        "\n",
        "class RelationNetwork(nn.Module):\n",
        "    \"\"\"docstring for RelationNetwork\"\"\"\n",
        "    def __init__(self,input_size,hidden_size):\n",
        "        super(RelationNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
        "                        nn.BatchNorm2d(64, momentum=1, affine=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2))\n",
        "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.sigmoid(self.fc2(out))\n",
        "        return out\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "    elif classname.find('Linear') != -1:\n",
        "        n = m.weight.size(1)\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        m.bias.data = torch.ones(m.bias.data.size())\n",
        "\n",
        "def main():\n",
        "    # Step 1: init data folders\n",
        "    print(\"init data folders\")\n",
        "    # init character folders for dataset construction\n",
        "    metatrain_character_folders,metatest_character_folders = tg.omniglot_character_folders()\n",
        "\n",
        "    # Step 2: init neural networks\n",
        "    print(\"init neural networks\")\n",
        "\n",
        "    feature_encoder = CNNEncoder()\n",
        "    relation_network = RelationNetwork(FEATURE_DIM,RELATION_DIM)\n",
        "\n",
        "    feature_encoder.apply(weights_init)\n",
        "    relation_network.apply(weights_init)\n",
        "\n",
        "    feature_encoder.cuda(GPU)\n",
        "    relation_network.cuda(GPU)\n",
        "\n",
        "    feature_encoder_optim = torch.optim.Adam(feature_encoder.parameters(),lr=LEARNING_RATE)\n",
        "    feature_encoder_scheduler = StepLR(feature_encoder_optim,step_size=100000,gamma=0.5)\n",
        "    relation_network_optim = torch.optim.Adam(relation_network.parameters(),lr=LEARNING_RATE)\n",
        "    relation_network_scheduler = StepLR(relation_network_optim,step_size=100000,gamma=0.5)\n",
        "\n",
        "    if os.path.exists(str(\"./models/omniglot_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "        feature_encoder.load_state_dict(torch.load(str(\"./models/omniglot_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "        print(\"load feature encoder success\")\n",
        "    if os.path.exists(str(\"./models/omniglot_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")):\n",
        "        relation_network.load_state_dict(torch.load(str(\"./models/omniglot_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\")))\n",
        "        print(\"load relation network success\")\n",
        "\n",
        "    # Step 3: build graph\n",
        "    print(\"Training...\")\n",
        "\n",
        "    last_accuracy = 0.0\n",
        "\n",
        "    for episode in range(EPISODE):\n",
        "\n",
        "        feature_encoder_scheduler.step(episode)\n",
        "        relation_network_scheduler.step(episode)\n",
        "\n",
        "        # init dataset\n",
        "        # sample_dataloader is to obtain previous samples for compare\n",
        "        # batch_dataloader is to batch samples for training\n",
        "        degrees = random.choice([0,90,180,270])\n",
        "        task = tg.OmniglotTask(metatrain_character_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,BATCH_NUM_PER_CLASS)\n",
        "        sample_dataloader = tg.get_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False,rotation=degrees)\n",
        "        batch_dataloader = tg.get_data_loader(task,num_per_class=BATCH_NUM_PER_CLASS,split=\"test\",shuffle=True,rotation=degrees)\n",
        "\n",
        "\n",
        "        # sample datas\n",
        "        samples,sample_labels = sample_dataloader.__iter__().next()\n",
        "        batches,batch_labels = batch_dataloader.__iter__().next()\n",
        "\n",
        "        # calculate features\n",
        "        sample_features = feature_encoder(Variable(samples).cuda(GPU)) # 5x64*5*5\n",
        "        sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,5,5)\n",
        "        sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "        batch_features = feature_encoder(Variable(batches).cuda(GPU)) # 20x64*5*5\n",
        "\n",
        "        # calculate relations\n",
        "        # each batch sample link to every samples to calculate relations\n",
        "        # to form a 100x128 matrix for relation network\n",
        "        sample_features_ext = sample_features.unsqueeze(0).repeat(BATCH_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
        "        batch_features_ext = batch_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
        "        batch_features_ext = torch.transpose(batch_features_ext,0,1)\n",
        "\n",
        "        relation_pairs = torch.cat((sample_features_ext,batch_features_ext),2).view(-1,FEATURE_DIM*2,5,5)\n",
        "        relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "        mse = nn.MSELoss().cuda(GPU)\n",
        "        one_hot_labels = Variable(torch.zeros(BATCH_NUM_PER_CLASS*CLASS_NUM, CLASS_NUM).scatter_(1, batch_labels.view(-1,1), 1)).cuda(GPU)\n",
        "        loss = mse(relations,one_hot_labels)\n",
        "\n",
        "\n",
        "        # training\n",
        "\n",
        "        feature_encoder.zero_grad()\n",
        "        relation_network.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm(feature_encoder.parameters(),0.5)\n",
        "        torch.nn.utils.clip_grad_norm(relation_network.parameters(),0.5)\n",
        "\n",
        "        feature_encoder_optim.step()\n",
        "        relation_network_optim.step()\n",
        "\n",
        "        if (episode+1)%100 == 0:\n",
        "                print(\"episode:\",episode+1,\"loss\",loss.data[0])\n",
        "\n",
        "        if (episode+1)%5000 == 0:\n",
        "\n",
        "            # test\n",
        "            print(\"Testing...\")\n",
        "            total_rewards = 0\n",
        "\n",
        "            for i in range(TEST_EPISODE):\n",
        "                degrees = random.choice([0,90,180,270])\n",
        "                task = tg.OmniglotTask(metatest_character_folders,CLASS_NUM,SAMPLE_NUM_PER_CLASS,SAMPLE_NUM_PER_CLASS,)\n",
        "                sample_dataloader = tg.get_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"train\",shuffle=False,rotation=degrees)\n",
        "                test_dataloader = tg.get_data_loader(task,num_per_class=SAMPLE_NUM_PER_CLASS,split=\"test\",shuffle=True,rotation=degrees)\n",
        "\n",
        "                sample_images,sample_labels = sample_dataloader.__iter__().next()\n",
        "                test_images,test_labels = test_dataloader.__iter__().next()\n",
        "\n",
        "                # calculate features\n",
        "                sample_features = feature_encoder(Variable(sample_images).cuda(GPU)) # 5x64\n",
        "                sample_features = sample_features.view(CLASS_NUM,SAMPLE_NUM_PER_CLASS,FEATURE_DIM,5,5)\n",
        "                sample_features = torch.sum(sample_features,1).squeeze(1)\n",
        "                test_features = feature_encoder(Variable(test_images).cuda(GPU)) # 20x64\n",
        "\n",
        "                # calculate relations\n",
        "                # each batch sample link to every samples to calculate relations\n",
        "                # to form a 100x128 matrix for relation network\n",
        "                sample_features_ext = sample_features.unsqueeze(0).repeat(SAMPLE_NUM_PER_CLASS*CLASS_NUM,1,1,1,1)\n",
        "                test_features_ext = test_features.unsqueeze(0).repeat(CLASS_NUM,1,1,1,1)\n",
        "                test_features_ext = torch.transpose(test_features_ext,0,1)\n",
        "\n",
        "                relation_pairs = torch.cat((sample_features_ext,test_features_ext),2).view(-1,FEATURE_DIM*2,5,5)\n",
        "                relations = relation_network(relation_pairs).view(-1,CLASS_NUM)\n",
        "\n",
        "                _,predict_labels = torch.max(relations.data,1)\n",
        "\n",
        "                rewards = [1 if predict_labels[j]==test_labels[j] else 0 for j in range(CLASS_NUM*SAMPLE_NUM_PER_CLASS)]\n",
        "\n",
        "                total_rewards += np.sum(rewards)\n",
        "\n",
        "            test_accuracy = total_rewards/1.0/CLASS_NUM/SAMPLE_NUM_PER_CLASS/TEST_EPISODE\n",
        "\n",
        "            print(\"test accuracy:\",test_accuracy)\n",
        "\n",
        "            if test_accuracy > last_accuracy:\n",
        "\n",
        "                # save networks\n",
        "                torch.save(feature_encoder.state_dict(),str(\"./models/omniglot_feature_encoder_\" + str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "                torch.save(relation_network.state_dict(),str(\"./models/omniglot_relation_network_\"+ str(CLASS_NUM) +\"way_\" + str(SAMPLE_NUM_PER_CLASS) +\"shot.pkl\"))\n",
        "\n",
        "                print(\"save networks for episode:\",episode)\n",
        "\n",
        "                last_accuracy = test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9_vTArwx9gq"
      },
      "source": [
        "# Tsne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cPmJq2Yx_iU"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr2ooTNnyZI9"
      },
      "outputs": [],
      "source": [
        "mnist = fetch_mldata(\"MNIST original\")\n",
        "X = mnist.data / 255.0\n",
        "y = mnist.target\n",
        "print(X.shape, y.shape)\n",
        "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
        "df = pd.DataFrame(X,columns=feat_cols)\n",
        "df['y'] = y\n",
        "df['label'] = df['y'].apply(lambda i: str(i))\n",
        "X, y = None, None\n",
        "print('Size of the dataframe: {}'.format(df.shape))\n",
        "# For reproducability of the results\n",
        "np.random.seed(42)\n",
        "rndperm = np.random.permutation(df.shape[0])\n",
        "\n",
        "plt.gray()\n",
        "fig = plt.figure( figsize=(16,7) )\n",
        "for i in range(0,15):\n",
        "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'label'])) )\n",
        "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
        "plt.show()\n",
        "\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(df[feat_cols].values)\n",
        "df['pca-one'] = pca_result[:,0]\n",
        "df['pca-two'] = pca_result[:,1] \n",
        "df['pca-three'] = pca_result[:,2]\n",
        "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.scatterplot(\n",
        "    x=\"pca-one\", y=\"pca-two\",\n",
        "    hue=\"y\",\n",
        "    palette=sns.color_palette(\"hls\", 10),\n",
        "    data=df.loc[rndperm,:],\n",
        "    legend=\"full\",\n",
        "    alpha=0.3\n",
        ")\n",
        "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
        "ax.scatter(\n",
        "    xs=df.loc[rndperm,:][\"pca-one\"], \n",
        "    ys=df.loc[rndperm,:][\"pca-two\"], \n",
        "    zs=df.loc[rndperm,:][\"pca-three\"], \n",
        "    c=df.loc[rndperm,:][\"y\"], \n",
        "    cmap='tab10'\n",
        ")\n",
        "ax.set_xlabel('pca-one')\n",
        "ax.set_ylabel('pca-two')\n",
        "ax.set_zlabel('pca-three')\n",
        "plt.show()\n",
        "N = 10000\n",
        "df_subset = df.loc[rndperm[:N],:].copy()\n",
        "data_subset = df_subset[feat_cols].values\n",
        "pca = PCA(n_components=3)\n",
        "pca_result = pca.fit_transform(data_subset)\n",
        "df_subset['pca-one'] = pca_result[:,0]\n",
        "df_subset['pca-two'] = pca_result[:,1] \n",
        "df_subset['pca-three'] = pca_result[:,2]\n",
        "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(data_subset)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
        "df_subset['tsne-2d-two'] = tsne_results[:,1]\n",
        "plt.figure(figsize=(16,10))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "    hue=\"y\",\n",
        "    palette=sns.color_palette(\"hls\", 10),\n",
        "    data=df_subset,\n",
        "    legend=\"full\",\n",
        "    alpha=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o-moxs1uZin"
      },
      "source": [
        "# Siamese Network Trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EFQoZ3I-vKk"
      },
      "outputs": [],
      "source": [
        "csv = pd.read_csv(\"/content/drive/MyDrive/Final Project/dataset/mnist/mnist_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2PeKbIruYYO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch as to\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "def secondval( value ):\n",
        "    \n",
        "    return value[0]\n",
        "\n",
        "class SiamDataset(Dataset):\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        # We import the MNIST dataset that is pre formatted and kept as a csv file \n",
        "        # in which each row contains a single image flattened out to 784 pixels\n",
        "        # so each row contains 784 entries\n",
        "        # after the import we reshape the image in the format required by pytorch i.e. (C,H,W)\n",
        "        \n",
        "\n",
        "        data = []\n",
        "        \n",
        "        img = csv.iloc[:,1:785]\n",
        "        #print(len(img))\n",
        "        #img = img.values\n",
        "        img = np.array(img).reshape(-1, 28, 28)\n",
        "        label = csv.iloc[:,0]\n",
        "        \n",
        "        self.img = {}\n",
        "        for i in range(len(img)):\n",
        "          if label[i] in self.img:\n",
        "            self.img[label[i]] = np.append(self.img[label[i]], img[i])\n",
        "          else:\n",
        "            self.img[label[i]] = img[i]\n",
        "        # Here we create a dictionary of images such that there are 10 keys \n",
        "        # each key is a class of the MNIST i.e. number b/w 0 & 9\n",
        "        # each key returns a list of all the images that is labelled after it\n",
        "        \n",
        "        # we first sort the data\n",
        "        # for i in range(len(img)):\n",
        "        #     data.append( [ label[i], img[i] ] )\n",
        "        \n",
        "        # data.sort(key = secondval)\n",
        "        \n",
        "        # self.len = len(img)\n",
        "        \n",
        "        # self.img = {}\n",
        "\n",
        "        # # here we create the dictionary as said above\n",
        "        # print(f\"data {np.array(data).shape}  \")\n",
        "        # for i in data:\n",
        "        #     print(i)\n",
        "        #     if i[0][0] not in self.img :\n",
        "        #         self.img[i[0][0]] = list()\n",
        "        #         self.img[i[0][0]].append(i[1])\n",
        "            \n",
        "        #     else :\n",
        "        #         self.img[i[0][0]].append(i[1])       \n",
        "        \n",
        "        # pass\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # this class is needed to be defined so that dataloader can be used\n",
        "        # here instead of giving the real index values I have returned randomly generated images\n",
        "        # so idx does not have any need but the function signature needs to be same so that the dataloader\n",
        "        # can call this function\n",
        "        \n",
        "        # I create a positive pair with label of similarity 1\n",
        "        \n",
        "        clas = np.random.randint(0,10)\n",
        "            \n",
        "        length = len(self.img[clas])\n",
        "        im1, im2 = np.random.randint(0,length,2)\n",
        "            \n",
        "        img1 = to.tensor(np.reshape(self.img[clas][im1],(1,28,28)), dtype=to.float32)\n",
        "        img2 = to.tensor(np.reshape(self.img[clas][im2],(1,28,28)), dtype=to.float32)\n",
        "        y1 = to.tensor(np.ones(1,dtype=np.float32),dtype=to.float32)\n",
        "        print(f\"y1 {y1}\")\n",
        "        # I create a negative pair with label of similarity 0\n",
        "        \n",
        "        len1 = len(self.img[clas])\n",
        "        clas2 = ( clas + np.random.randint(0,9) ) % 9\n",
        "        len2 = len(self.img[clas2])\n",
        "            \n",
        "        im3 = np.random.randint(0,len1)\n",
        "        im4 = np.random.randint(0,len2)\n",
        "            \n",
        "        img3 = to.tensor(np.reshape(self.img[clas][im3],(1,28,28)), dtype=to.float32)\n",
        "        img4 = to.tensor(np.reshape(self.img[clas2][im4],(1,28,28)), dtype=to.float32)\n",
        "        y2 = to.tensor(np.zeros(1,dtype=np.float32),dtype=to.float32)\n",
        "            \n",
        "        return  img1, img2, y1, img3, img4, y2\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return 10000\n",
        "\n",
        "class Siamese(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Siamese,self).__init__()\n",
        "        \n",
        "        # A simple two layer convolution followed by three fully connected layers should do\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d( kernel_size=2, stride=2)\n",
        "        self.pool2 = nn.MaxPool2d( kernel_size=3)\n",
        "        \n",
        "        self.lin1 = nn.Linear(144, 64)\n",
        "        self.lin2 = nn.Linear(64, 32)\n",
        "        self.lin3 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward_once(self,x):\n",
        "        \n",
        "        # forwarding the input through the layers\n",
        "          \n",
        "        out = self.pool1(nn.functional.relu(self.conv1(x)))\n",
        "        out = self.pool2(nn.functional.relu(self.conv2(out)))\n",
        "        \n",
        "        out = out.view(-1,144)\n",
        "        \n",
        "        out = nn.functional.relu(self.lin1(out))\n",
        "        out = nn.functional.relu(self.lin2(out))\n",
        "        out = self.lin3(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    def forward(self, x, y):    \n",
        "        \n",
        "        # doing the forwarding twice so as to obtain the same functions as that of twin networks\n",
        "        \n",
        "        out1 = self.forward_once(x)\n",
        "        out2 = self.forward_once(y)\n",
        "        \n",
        "        return out1, out2\n",
        "    \n",
        "    \n",
        "    def evaluate(self, x, y):\n",
        "        \n",
        "        # this can be used later for evalutation\n",
        "        \n",
        "        m = to.tensor(1.0, dtype=to.float32)\n",
        "        \n",
        "        if type(m) != type(x):\n",
        "            x = to.tensor(x, dtype = to.float32, requires_grad = False)\n",
        "            \n",
        "        if type(m) != type(y):\n",
        "            y = to.tensor(y, dtype = to.float32, requires_grad = False)\n",
        "        \n",
        "        x = x.view(-1,1,28,28)\n",
        "        y = y.view(-1,1,28,28)\n",
        "        \n",
        "        with to.no_grad():\n",
        "            \n",
        "            out1, out2 = self.forward(x, y)\n",
        "            \n",
        "            return nn.functional.pairwise_distance(out1, out2)\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        " \n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        \n",
        "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
        "        \n",
        "        loss_contrastive = to.mean((1-label) * to.pow(euclidean_distance, 2) +\n",
        "                                      (label) * to.pow(to.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "        return loss_contrastive\n",
        "\n",
        "siamdset = SiamDataset()\n",
        "\n",
        "train_dataloader = DataLoader(siamdset, shuffle=True, batch_size= 16,\n",
        "                        num_workers=8)\n",
        "\n",
        "siam = Siamese()\n",
        "number_epochs = 200\n",
        "Criterion = ContrastiveLoss()\n",
        "Optimizer = to.optim.Adam(siam.parameters(),lr = 0.001 )\n",
        "counter = []\n",
        "loss_history = [] \n",
        "iteration_number= 0\n",
        "print(f\"train_dataloader {train_dataloader}\")\n",
        "for epoch in range(0,number_epochs):\n",
        "    for data in train_dataloader:\n",
        "   \n",
        "        img1, img2 , label1, img3, img4, label2 = data\n",
        "        print(f\"img1 shpae {img1.shape}\")\n",
        "        Optimizer.zero_grad()\n",
        "        \n",
        "        # here we obtain the positive pairs' loss as well as the negative pairs' loss\n",
        "        \n",
        "        output1,output2 = siam(img1,img2)\n",
        "        output3,output4 = siam(img3,img4)\n",
        "        \n",
        "        loss_pos = Criterion(output1,output2,label1)\n",
        "        loss_neg = Criterion(output3,output4,label2)\n",
        "        \n",
        "        # the total loss is then computed and back propagated\n",
        "        \n",
        "        loss_contrastive = loss_pos + loss_neg\n",
        "        \n",
        "        loss_contrastive.backward()\n",
        "        \n",
        "        Optimizer.step()\n",
        "    \n",
        "    # printing the training errors\n",
        "    \n",
        "    print(\"Epoch number {}\\n  Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
        "    counter.append(epoch+100)\n",
        "    loss_history.append(loss_contrastive.item())\n",
        "    to.save(siam.state_dict(), \"./Siamese model\")\n",
        "\n",
        "#Testing the model's prediction\n",
        "!%matplotlib inline\n",
        "\n",
        "trial = list()\n",
        "\n",
        "for i in range(0,5):\n",
        "    trial.append(siamdset[i])\n",
        "\n",
        "fig = plt.figure(1, figsize=(30,30))\n",
        "\n",
        "i = 1 \n",
        "\n",
        "for data in trial :\n",
        "\n",
        "    im1, im2, lb1, im3, im4, lb2 = data\n",
        "\n",
        "    diss1 = siam.evaluate(im1,im2)\n",
        "    diss2 = siam.evaluate(im3,im4)\n",
        "    \n",
        "    im1 = np.concatenate((im1.numpy()[0],im2.numpy()[0]),axis=1)\n",
        "    lb1 = lb1.numpy()\n",
        "    \n",
        "    im2 = np.concatenate((im3.numpy()[0],im4.numpy()[0]),axis=1)\n",
        "    lb2 = lb2.numpy()\n",
        "    \n",
        "    diss1 = diss1.numpy()\n",
        "    diss2 = diss2.numpy()\n",
        "\n",
        "    ax1 = fig.add_subplot(10,4,i)\n",
        "    ax1.title.set_text(\"label = \"+str(lb1[0])+\"\\n\"+\"sim = \"+str(diss1[0]))\n",
        "    ax1.imshow(im1)\n",
        "    \n",
        "    ax2 = fig.add_subplot(10,4,i+1)\n",
        "    ax2.title.set_text(\"label = \"+str(lb2[0])+\"\\n\"+\"sim = \"+str(diss2[0]))\n",
        "    ax2.imshow(im2)\n",
        "\n",
        "    i+=8\n",
        "\n",
        "\n",
        "plt.show()   \n",
        "fig.savefig(\"./plot/Siamese_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iba0OkPNC_H"
      },
      "source": [
        "#Rough Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiiLongHL4d_"
      },
      "outputs": [],
      "source": [
        "print(np.arange(1, 100, 1, dtype=int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRulh6SSPwCn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVeGpdNaPzun"
      },
      "outputs": [],
      "source": [
        "print(f\"adj_matrix {type(adj_matrix)}\")\n",
        "print(f\"adj_matrix {adj_matrix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIs63FzRPGEx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ou23U88LnQv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def show_graph_with_labels(adjacency_matrix, mylabels):\n",
        "    edges = adjacency_matrix\n",
        "    gr = nx.Graph()\n",
        "    gr.add_edges_from(edges)\n",
        "    nx.draw(gr, node_size=500, labels=mylabels, with_labels=True)\n",
        "    plt.show()\n",
        "\n",
        "show_graph_with_labels(adj_matrix, np.arange(1, 100, 1, dtype=int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9UZaXK-vnu9"
      },
      "outputs": [],
      "source": [
        "random.sample(list(np.arange(10)), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5yTMMZ_pO1z"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "\n",
        "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
        "for i in range(4):\n",
        "  G = GraphVisualization(dataset[i])\n",
        "  G.visualize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNCnWDoVpagK"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLfJVqK24fIN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_frPpp32-R-"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "from PIL import Image\n",
        "# load the image and convert it to a floating point data type\n",
        "image = img_as_float(Image.fromarray(trainX[0]).resize((28,28)))\n",
        "\n",
        "# apply SLIC and extract (approximately) the supplied number\n",
        "# of segments\n",
        "segments = slic(image, n_segments = 75, sigma = 2)\n",
        "print(np.array(segments).shape)\n",
        "#print(segments[18])\n",
        "# show the output of SLIC\n",
        "fig = plt.figure(\"Superpixels\")\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.imshow(mark_boundaries(image, segments))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z34dRTD25wde"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "# load the image and convert it to a floating point data type\n",
        "image = img_as_float(io.imread(\"Screenshot_2.jpg\"))\n",
        "\n",
        "# apply SLIC and extract (approximately) the supplied number\n",
        "# of segments\n",
        "segments = slic(image, n_segments = 450, sigma = 5)\n",
        "print(np.array(segments).shape)\n",
        "print(segments[18])\n",
        "# show the output of SLIC\n",
        "fig = plt.figure(\"Superpixels\")\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.imshow(mark_boundaries(image, segments))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9EhDWDd8ueO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade segraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4FoMelZ9LXG"
      },
      "outputs": [],
      "source": [
        "def create_graph(grid):\n",
        "    \"\"\"\n",
        "    This function creates a graph of vertices and edges from segments returned by SLIC.\n",
        "    :param array grid: A grid of segments as returned by the slic function defined in skimage library\n",
        "    :return: A graph as [vertices, edges]\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import numpy as np\n",
        "    except ImportError:\n",
        "        print(\n",
        "            \"NumPY is not installed. segraph needs NumPY to function. Please use 'pip install numpy' to install numpy.\")\n",
        "        exit(0)\n",
        "    print(\"Creating a graph using segmented grid..\")\n",
        "    # get an array of unique labels\n",
        "    try:\n",
        "        vertices = np.unique(grid)\n",
        "\n",
        "        # get number of vertices\n",
        "        num_vertices = len(vertices)\n",
        "\n",
        "        # map these unique labels to [1,...,N], where N is the number of labels (vertices)\n",
        "        mapping = dict(zip(vertices, np.arange(num_vertices)))\n",
        "        mapped_grid = np.array([mapping[x] for x in grid.flat]).reshape(grid.shape)\n",
        "\n",
        "        # create edges, going left to right and top to bottom\n",
        "        l2r = np.c_[mapped_grid[:, :-1].ravel(), mapped_grid[:, 1:].ravel()]\n",
        "        t2b = np.c_[mapped_grid[:-1, :].ravel(), mapped_grid[1:, :].ravel()]\n",
        "\n",
        "        # stack for entire graph\n",
        "        edges = np.vstack([l2r, t2b])\n",
        "        edges = edges[edges[:, 0] != edges[:, 1], :]\n",
        "        edges = np.sort(edges, axis=1)\n",
        "\n",
        "        # create a edge map, a hashmap\n",
        "        edge_map = edges[:, 0] + num_vertices * edges[:, 1]\n",
        "\n",
        "        # filter unique connections as edges\n",
        "        edges = np.unique(edge_map)\n",
        "\n",
        "        # reverse map and form edges as pairs\n",
        "        edges = [[vertices[edge % num_vertices],\n",
        "                  vertices[edge // num_vertices]] for edge in edges]\n",
        "    except:\n",
        "        print(\"Invalid argument supplied !\")\n",
        "        return None\n",
        "\n",
        "    return vertices, edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSC_VGVW8wK3"
      },
      "outputs": [],
      "source": [
        "from skimage.segmentation import slic\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io as skimageIO\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "image = img_as_float(skimageIO.imread(\"Screenshot_2.jpg\"))\n",
        "segments = slic(image, n_segments=100, sigma=1.0)\n",
        "vertices, edges = create_graph(segments)\n",
        "print(segments.shape)\n",
        "# Create graph of superpixels \n",
        "\n",
        "\n",
        "# show the output of SLIC\n",
        "fig = plt.figure(\"Superpixels\")\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.imshow(mark_boundaries(image, segments))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# show the plots\n",
        "plt.show()\n",
        "# # Compute centers:\n",
        "# gridx, gridy = np.mgrid[:segments.shape[0], :segments.shape[1]]\n",
        "# centers = dict()\n",
        "# for v in vertices:\n",
        "#     centers[v] = [gridy[segments == v].mean(), gridx[segments == v].mean()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZzhWdrV9XFs"
      },
      "outputs": [],
      "source": [
        "# Defining a Class\n",
        "class GraphVisualization:\n",
        "   \n",
        "    def __init__(self,graph):\n",
        "          \n",
        "        # visual is a list which stores all \n",
        "        # the set of edges that constitutes a\n",
        "        # graph\n",
        "        self.visual = graph['edge_index'].numpy().reshape(-1,2)\n",
        "        self.labels = graph['x']\n",
        "        self.label_dict = {}\n",
        "        for idx,label in enumerate(self.labels):\n",
        "          self.label_dict[idx] = str(idx)#+\" : \" + str(label.numpy()[0])\n",
        "          \n",
        "    # In visualize function G is an object of\n",
        "    # class Graph given by networkx G.add_edges_from(visual)\n",
        "    # creates a graph with a given list\n",
        "    # nx.draw_networkx(G) - plots the graph\n",
        "    # plt.show() - displays the graph\n",
        "    def visualize(self):\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(self.visual)\n",
        "        nx.draw_networkx(G, node_size=100, labels=self.label_dict, with_labels=True)\n",
        "        plt.show()\n",
        "#Driver Code\n",
        "#Creating a basic graph using Pytorch Geometric\n",
        "\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "x = torch.tensor(vertices, dtype=int)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "G = GraphVisualization(data)\n",
        "G.visualize()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "(Latest) Final_Year_Project",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}